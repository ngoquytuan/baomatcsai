# üéØ CHECKLIST & RULES CHO M·ªåI D·ª∞ √ÅN MACHINE LEARNING

ƒê√¢y l√† **BEST PRACTICES** chung cho h·∫ßu h·∫øt d·ª± √°n ML, kh√¥ng ri√™ng g√¨ b√†i to√°n security .

---

## üìã ML PROJECT CHECKLIST - PHI√äN B·∫¢N ƒê·∫¶Y ƒê·ª¶

---

## ‚úÖ PHASE 1: HI·ªÇU B√ÄI TO√ÅN (PROBLEM UNDERSTANDING)

### **1.1 X√°c ƒë·ªãnh lo·∫°i b√†i to√°n**
- [ ] Classification (ph√¢n lo·∫°i)
  - [ ] Binary (2 classes): spam/not spam, fraud/normal
  - [ ] Multiclass (>2 classes): cat/dog/bird
  - [ ] Multilabel (nhi·ªÅu labels c√πng l√∫c)
- [ ] Regression (d·ª± ƒëo√°n s·ªë): gi√° nh√†, nhi·ªát ƒë·ªô
- [ ] Clustering (ph√¢n nh√≥m): ph√¢n kh√°ch h√†ng
- [ ] Anomaly Detection (ph√°t hi·ªán b·∫•t th∆∞·ªùng)
- [ ] Time Series (d·ªØ li·ªáu theo th·ªùi gian)

### **1.2 X√°c ƒë·ªãnh success metrics**
- [ ] Ch·ªçn metric ph√π h·ª£p v·ªõi business:
  - Classification: Accuracy, Precision, Recall, F1, AUC-ROC
  - Regression: MAE, MSE, RMSE, R¬≤
  - Ranking: MAP, NDCG
- [ ] X√°c ƒë·ªãnh threshold ch·∫•p nh·∫≠n ƒë∆∞·ª£c (VD: accuracy >90%)
- [ ] X√°c ƒë·ªãnh y√™u c·∫ßu v·ªÅ inference time (<100ms?)
- [ ] X√°c ƒë·ªãnh cost c·ªßa False Positive vs False Negative

### **1.3 Thu th·∫≠p y√™u c·∫ßu**
- [ ] ƒê·ªô ch√≠nh x√°c c·∫ßn thi·∫øt
- [ ] T·ªëc ƒë·ªô inference
- [ ] K√≠ch th∆∞·ªõc model t·ªëi ƒëa
- [ ] Kh·∫£ nƒÉng gi·∫£i th√≠ch (interpretability)
- [ ] ƒêi·ªÅu ki·ªán deploy (cloud, edge, mobile)

---

## ‚úÖ PHASE 2: THU TH·∫¨P & PH√ÇN T√çCH D·ªÆ LI·ªÜU (DATA COLLECTION)

### **2.1 Thu th·∫≠p data**
- [ ] X√°c ƒë·ªãnh ngu·ªìn data: Production logs, APIs, Databases, Public datasets
- [ ] ƒê·∫£m b·∫£o data ƒë·ªß l·ªõn (rule of thumb: 10-50 samples/feature t·ªëi thi·ªÉu)
- [ ] Ki·ªÉm tra quy·ªÅn s·ª≠ d·ª•ng data (privacy, GDPR, licenses)
- [ ] Document data source v√† collection method

### **2.2 Exploratory Data Analysis (EDA)**
- [ ] Load data v√† check shape: `df.shape`
- [ ] Check data types: `df.dtypes`
- [ ] Check missing values: `df.isnull().sum()`
- [ ] Check duplicates: `df.duplicated().sum()`
- [ ] Statistical summary: `df.describe()`
- [ ] Visualize distributions: histograms, box plots
- [ ] Check correlations: `df.corr()`
- [ ] Identify outliers

### **2.3 Label Distribution (cho classification)**
- [ ] Check imbalanced data: `df['label'].value_counts()`
- [ ] N·∫øu imbalanced (<30% minority class):
  - [ ] Consider SMOTE, oversampling, undersampling
  - [ ] Consider class weights
  - [ ] Consider anomaly detection approach
  - [ ] Use stratified split

---

## ‚úÖ PHASE 3: FEATURE ENGINEERING

### **3.1 Feature Selection**
- [ ] Domain expertise: Ch·ªçn features c√≥ √Ω nghƒ©a business
- [ ] Remove low-variance features
- [ ] Remove highly correlated features (>0.95)
- [ ] Feature importance analysis
- [ ] Curse of dimensionality: Kh√¥ng qu√° nhi·ªÅu features so v·ªõi samples

### **3.2 Feature Creation**
- [ ] T·∫°o interaction features n·∫øu c·∫ßn
- [ ] Binning/discretization cho continuous features
- [ ] Encoding categorical features:
  - [ ] One-hot encoding (cho nominal)
  - [ ] Label encoding (cho ordinal)
  - [ ] Target encoding (c·∫©n th·∫≠n data leakage)
- [ ] Date/time features: hour, day_of_week, month, is_weekend
- [ ] Text features: TF-IDF, word embeddings

### **3.3 Feature Validation**
- [ ] ƒê·∫£m b·∫£o features c√≥ th·ªÉ thu th·∫≠p ·ªü production
- [ ] Kh√¥ng d√πng features c√≥ data leakage
- [ ] Kh√¥ng d√πng features vi ph·∫°m privacy

---

## ‚úÖ PHASE 4: DATA SPLITTING (QUAN TR·ªåNG!)

### **4.1 Train/Validation/Test Split**
**RULE 1: Lu√¥n chia data TR∆Ø·ªöC KHI l√†m b·∫•t c·ª© ƒëi·ªÅu g√¨ kh√°c!**

```python
# C√°ch 1: Train/Test split (ƒë∆°n gi·∫£n)
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,        # RULE 2: Th∆∞·ªùng 0.2 ho·∫∑c 0.3
    random_state=42,      # RULE 3: Lu√¥n set ƒë·ªÉ reproducible
    stratify=y            # RULE 4: V·ªõi classification, lu√¥n stratify
)

# C√°ch 2: Train/Val/Test split (khuy·∫øn kh√≠ch)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
)
# K·∫øt qu·∫£: 60% train, 20% val, 20% test
```

### **4.2 Split Rules chi ti·∫øt**

**RULE 2: test_size ph·ª• thu·ªôc dataset size**
```
Dataset Size         Recommended Split
< 1,000             70/30 ho·∫∑c 80/20
1,000 - 10,000      80/20
10,000 - 100,000    85/15 ho·∫∑c 90/10
> 100,000           90/10 ho·∫∑c 95/5
```

**RULE 3: random_state**
- [ ] Lu√¥n set random_state (VD: 42, 123, 2024)
- [ ] Gi√∫p reproduce k·∫øt qu·∫£
- [ ] D√πng c√πng m·ªôt gi√° tr·ªã trong su·ªët project
- [ ] Document gi√° tr·ªã ƒë√£ ch·ªçn

**RULE 4: stratify cho classification**
- [ ] Lu√¥n d√πng `stratify=y` v·ªõi classification
- [ ] ƒê·∫£m b·∫£o t·ª∑ l·ªá class gi·ªëng nhau gi·ªØa train/val/test
- [ ] ƒê·∫∑c bi·ªát quan tr·ªçng v·ªõi imbalanced data

**RULE 5: Time-based split cho time series**
```python
# KH√îNG d√πng random split v·ªõi time series!
# D√πng time-based split:
train = df[df['date'] < '2024-01-01']
test = df[df['date'] >= '2024-01-01']
```

### **4.3 Data Leakage Prevention (C·ª∞C K·ª≤ QUAN TR·ªåNG!)**

**RULE 6: KH√îNG BAO GI·ªú ƒë·ªÉ test data "nh√¨n th·∫•y" trong training!**

```python
# ‚ùå SAI - Fit scaler tr√™n to√†n b·ªô data
scaler.fit(X)  # Leak test data info!
X_train, X_test = train_test_split(X)

# ‚úÖ ƒê√öNG - Fit ch·ªâ tr√™n training data
X_train, X_test = train_test_split(X)
scaler.fit(X_train)  # Ch·ªâ h·ªçc t·ª´ train
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

**RULE 7: Ki·ªÉm tra overlap**
```python
train_set = set(map(tuple, X_train.values))
test_set = set(map(tuple, X_test.values))
overlap = train_set & test_set
assert len(overlap) == 0, "Data leakage detected!"
```

---

## ‚úÖ PHASE 5: DATA PREPROCESSING

### **5.1 Handle Missing Values**
- [ ] Identify missing patterns: `df.isnull().sum()`
- [ ] Decide strategy:
  - [ ] Drop rows (n·∫øu <5% missing)
  - [ ] Imputation: mean, median, mode
  - [ ] Advanced: KNN imputer, iterative imputer
  - [ ] Create "missing" indicator feature
- [ ] **RULE 8: Fit imputer ch·ªâ tr√™n training data!**

### **5.2 Handle Outliers**
- [ ] Detect: IQR method, Z-score
- [ ] Decide: Keep, cap, remove, transform
- [ ] Document outlier handling strategy

### **5.3 Feature Scaling**
**RULE 9: Scaling rules theo algorithm**

| Algorithm | Scaling c·∫ßn? | Method |
|-----------|--------------|--------|
| Logistic Regression | ‚úÖ C·∫¶N | StandardScaler |
| SVM | ‚úÖ C·∫¶N | StandardScaler |
| Neural Networks | ‚úÖ C·∫¶N | StandardScaler ho·∫∑c MinMaxScaler |
| KNN | ‚úÖ C·∫¶N | StandardScaler |
| Naive Bayes | ‚ùå KH√îNG | - |
| Decision Tree | ‚ùå KH√îNG | - |
| Random Forest | ‚ùå KH√îNG | - |
| XGBoost | ‚ùå KH√îNG | - |

**RULE 10: Fit scaler ch·ªâ tr√™n training!**
```python
# ‚úÖ ƒê√öNG
scaler = StandardScaler()
scaler.fit(X_train)  # Ch·ªâ h·ªçc t·ª´ train
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ‚ùå SAI
scaler.fit(pd.concat([X_train, X_test]))  # Leak!
```

**StandardScaler vs MinMaxScaler:**
```
StandardScaler: (x - mean) / std
- K·∫øt qu·∫£: mean=0, std=1
- D√πng khi: Data c√≥ outliers, distribution t∆∞∆°ng ƒë·ªëi normal

MinMaxScaler: (x - min) / (max - min)
- K·∫øt qu·∫£: range [0, 1]
- D√πng khi: C·∫ßn bounded range, neural networks v·ªõi sigmoid/tanh
```

---

## ‚úÖ PHASE 6: MODEL SELECTION & TRAINING

### **6.1 Baseline Model**
**RULE 11: Lu√¥n b·∫Øt ƒë·∫ßu v·ªõi baseline ƒë∆°n gi·∫£n!**
- [ ] Classification: Dummy classifier (most frequent)
- [ ] Regression: Mean/median predictor
- [ ] M·ª•c ƒë√≠ch: C√≥ baseline ƒë·ªÉ so s√°nh

### **6.2 Ch·ªçn Algorithms**
**RULE 12: Ch·ªçn algorithm ph√π h·ª£p v·ªõi b√†i to√°n**

**Cho Classification:**
```
Dataset nh·ªè (<10K):
‚îú‚îÄ Linear data ‚Üí Logistic Regression
‚îú‚îÄ Non-linear ‚Üí SVM with RBF kernel
‚îî‚îÄ Tree-based ‚Üí Random Forest, XGBoost

Dataset l·ªõn (>10K):
‚îú‚îÄ Deep Learning n·∫øu c√≥: images, text, complex patterns
‚îú‚îÄ XGBoost/LightGBM cho tabular data
‚îî‚îÄ Ensemble methods
```

**Cho Regression:**
```
‚îú‚îÄ Linear Regression (baseline)
‚îú‚îÄ Ridge/Lasso (n·∫øu c√≥ nhi·ªÅu features)
‚îú‚îÄ Random Forest Regressor
‚îú‚îÄ XGBoost/LightGBM
‚îî‚îÄ Neural Networks (dataset l·ªõn)
```

### **6.3 Training Strategy**
**RULE 13: Train nhi·ªÅu models v√† so s√°nh**
- [ ] √çt nh·∫•t 3-5 algorithms kh√°c nhau
- [ ] So s√°nh tr√™n validation set
- [ ] Track training time, model size, inference speed

**RULE 14: Cross-validation cho dataset nh·ªè**
```python
from sklearn.model_selection import cross_val_score

# K-fold CV (th∆∞·ªùng k=5 ho·∫∑c 10)
scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
print(f"CV Accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})")
```

**Khi n√†o d√πng CV:**
- Dataset nh·ªè (<5000 samples)
- C·∫ßn ƒë√°nh gi√° robust
- C√≥ th·ªùi gian training

**Khi n√†o KH√îNG d√πng CV:**
- Dataset l·ªõn (>50K) ‚Üí Ch·ªâ c·∫ßn train/val/test split
- Time series data ‚Üí D√πng TimeSeriesSplit
- Production v·ªõi time constraints

---

## ‚úÖ PHASE 7: MODEL EVALUATION

### **7.1 Evaluation Metrics**
**RULE 15: D√πng nhi·ªÅu metrics, kh√¥ng ch·ªâ accuracy!**

**Classification:**
```python
from sklearn.metrics import classification_report, confusion_matrix

# Must-have metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print(f"TN={cm[0,0]}, FP={cm[0,1]}")
print(f"FN={cm[1,0]}, TP={cm[1,1]}")

# Advanced
roc_auc = roc_auc_score(y_test, y_proba)
```

**RULE 16: Hi·ªÉu trade-offs c·ªßa t·ª´ng metric**
```
Accuracy: T·ªïng quan, nh∆∞ng sai l·ªách v·ªõi imbalanced data
Precision: "Trong c√°c d·ª± ƒëo√°n positive, c√≥ bao nhi√™u ƒë√∫ng?"
          ‚Üí Quan tr·ªçng khi False Positive t·ªën k√©m
Recall: "Trong c√°c positive th·∫≠t, b·∫Øt ƒë∆∞·ª£c bao nhi√™u?"
       ‚Üí Quan tr·ªçng khi False Negative nguy hi·ªÉm (security, medical)
F1: C√¢n b·∫±ng Precision v√† Recall
```

**RULE 17: Ch·ªçn metric theo business context**
```
Spam detection: Precision cao (√≠t x√≥a nh·∫ßm email quan tr·ªçng)
Cancer detection: Recall cao (kh√¥ng b·ªè s√≥t b·ªánh nh√¢n)
Fraud detection: F1 ho·∫∑c Recall cao (kh√¥ng b·ªè s√≥t gian l·∫≠n)
Recommendation: MAP, NDCG
```

### **7.2 Confusion Matrix Analysis**
**RULE 18: Lu√¥n ph√¢n t√≠ch confusion matrix chi ti·∫øt**
```
                 Predicted
              Negative  Positive
Actual Neg      TN        FP      ‚Üê Type I Error
       Pos      FN        TP      ‚Üê Type II Error

FP (False Positive): B√°o ƒë·ªông gi·∫£ ‚Üí L√†m phi·ªÅn user
FN (False Negative): B·ªè s√≥t ‚Üí Nguy hi·ªÉm!
```

### **7.3 Learning Curves**
- [ ] Plot training vs validation curves
- [ ] Identify overfitting/underfitting
- [ ] Decide next steps

---

## ‚úÖ PHASE 8: HYPERPARAMETER TUNING

### **8.1 Tuning Strategy**
**RULE 19: Tune tr√™n validation set, KH√îNG ph·∫£i test set!**

```python
# ‚ùå SAI - Tune tr√™n test set
best_params = tune_on_test_set()  # Test set leak!

# ‚úÖ ƒê√öNG - Tune tr√™n validation set
best_params = tune_on_validation_set()
final_test = evaluate_on_test_set(best_params)
```

### **8.2 Tuning Methods**
**RULE 20: B·∫Øt ƒë·∫ßu v·ªõi Grid Search, sau ƒë√≥ Random Search**

```python
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

# Grid Search (nh·ªè, exhaustive)
param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['rbf', 'linear']
}
grid = GridSearchCV(SVM(), param_grid, cv=5)

# Random Search (l·ªõn, faster)
param_dist = {
    'n_estimators': [50, 100, 200, 500],
    'max_depth': [5, 10, 20, None],
    'min_samples_split': [2, 5, 10]
}
random = RandomizedSearchCV(RF(), param_dist, n_iter=20, cv=5)
```

**Advanced: Bayesian Optimization**
- D√πng cho expensive models (deep learning)
- Libraries: Optuna, Hyperopt

### **8.3 Overfitting Prevention**
**RULE 21: Watch out for overfitting signs**
```
Signs:
- Train accuracy >> Test accuracy (>10% gap)
- Model qu√° ph·ª©c t·∫°p
- Training loss gi·∫£m nh∆∞ng val loss tƒÉng

Solutions:
- Regularization (L1, L2, dropout)
- Reduce model complexity
- Get more data
- Data augmentation
- Early stopping
```

---

## ‚úÖ PHASE 9: MODEL COMPARISON

### **9.1 Comparison Criteria**
**RULE 22: So s√°nh ƒëa chi·ªÅu, kh√¥ng ch·ªâ accuracy**

| Model | Accuracy | Precision | Recall | F1 | Training Time | Inference Time | Model Size |
|-------|----------|-----------|--------|----|--------------:|---------------:|-----------:|
| LR | 0.85 | 0.83 | 0.87 | 0.85 | 0.1s | 0.001s | 1 KB |
| RF | 0.92 | 0.90 | 0.94 | 0.92 | 5s | 0.05s | 500 KB |
| NN | 0.93 | 0.91 | 0.95 | 0.93 | 300s | 0.02s | 10 MB |

### **9.2 Selection Criteria**
- [ ] Performance metrics (primary)
- [ ] Inference speed (production requirement)
- [ ] Model size (deployment constraint)
- [ ] Interpretability (business requirement)
- [ ] Training time (iteration speed)
- [ ] Maintenance cost

---

## ‚úÖ PHASE 10: FINAL EVALUATION

### **10.1 Test Set Evaluation**
**RULE 23: Test set ch·ªâ d√πng M·ªòT L·∫¶N cu·ªëi c√πng!**
```python
# ‚ùå SAI - Test nhi·ªÅu l·∫ßn
for model in models:
    test_score = evaluate(model, X_test, y_test)
    if test_score > best:
        best_model = model  # Overfitting to test set!

# ‚úÖ ƒê√öNG - Select tr√™n validation, test cu·ªëi
best_model = select_on_validation()
final_score = evaluate_once(best_model, X_test, y_test)
```

### **10.2 Final Checks**
- [ ] Evaluate tr√™n test set M·ªòT L·∫¶N duy nh·∫•t
- [ ] Document t·∫•t c·∫£ metrics
- [ ] Verify model meets requirements
- [ ] Test edge cases
- [ ] Analyze errors (FP, FN cases)

---

## ‚úÖ PHASE 11: MODEL DEPLOYMENT

### **11.1 Model Saving**
**RULE 24: Save model v√† preprocessing objects**
```python
import pickle

# Save model
pickle.dump(model, open('model.pkl', 'wb'))

# Save scaler (QUAN TR·ªåNG!)
pickle.dump(scaler, open('scaler.pkl', 'wb'))

# Save feature names
pickle.dump(feature_names, open('features.pkl', 'wb'))
```

### **11.2 Inference Pipeline**
```python
def predict_new_data(new_data):
    # 1. Load model v√† scaler
    model = pickle.load(open('model.pkl', 'rb'))
    scaler = pickle.load(open('scaler.pkl', 'rb'))
    
    # 2. Preprocessing (gi·ªëng training!)
    new_data_scaled = scaler.transform(new_data)
    
    # 3. Predict
    prediction = model.predict(new_data_scaled)
    probability = model.predict_proba(new_data_scaled)
    
    return prediction, probability
```

### **11.3 Production Checklist**
- [ ] API endpoint ready
- [ ] Input validation
- [ ] Error handling
- [ ] Logging
- [ ] Monitoring setup
- [ ] A/B testing plan
- [ ] Rollback plan

---

## ‚úÖ PHASE 12: MONITORING & MAINTENANCE

### **12.1 Model Monitoring**
**RULE 25: Lu√¥n monitor model trong production**
- [ ] Track performance metrics daily/weekly
- [ ] Monitor data drift
- [ ] Monitor concept drift
- [ ] Set up alerts for anomalies

### **12.2 Retraining Strategy**
- [ ] Schedule periodic retraining
- [ ] Retrain when performance drops >5%
- [ ] Retrain when data distribution changes
- [ ] Version control for models

---

## üìã QUICK CHECKLIST - IN RA D√ÅN T∆Ø·ªúNG

```
‚ñ° Hi·ªÉu b√†i to√°n & ch·ªçn metrics
‚ñ° EDA: shape, dtypes, missing, distribution, correlation
‚ñ° Split data: train/val/test (stratify n·∫øu classification)
‚ñ° Check data leakage: overlap = 0
‚ñ° Handle missing values (fit tr√™n train only)
‚ñ° Feature engineering & selection
‚ñ° Scaling (fit tr√™n train only, theo algorithm)
‚ñ° Train baseline model
‚ñ° Train multiple models (3-5)
‚ñ° Cross-validation (dataset nh·ªè)
‚ñ° Evaluate v·ªõi nhi·ªÅu metrics
‚ñ° Ph√¢n t√≠ch confusion matrix
‚ñ° Hyperparameter tuning (tr√™n validation)
‚ñ° So s√°nh models ƒëa chi·ªÅu
‚ñ° Final test evaluation (M·ªòT L·∫¶N)
‚ñ° Save model + scaler + features
‚ñ° Deploy v·ªõi monitoring
‚ñ° Set up retraining pipeline
```

---

## üö® TOP 10 L·ªñI TH∆Ø·ªúNG G·∫∂P

1. **Data Leakage** - Fit scaler/imputer tr√™n to√†n b·ªô data
2. **Kh√¥ng stratify** - Class imbalance gi·ªØa train/test
3. **Qu√™n set random_state** - K·∫øt qu·∫£ kh√¥ng reproducible
4. **Overfit to test set** - Test nhi·ªÅu l·∫ßn v√† ch·ªçn best
5. **Ch·ªâ nh√¨n accuracy** - B·ªè qua precision, recall, F1
6. **Kh√¥ng check imbalanced data** - Accuracy gi·∫£ t·∫°o cao
7. **Scaling sai** - Scale test data ƒë·ªôc l·∫≠p train
8. **Qu√™n save scaler** - Production kh√¥ng scale ƒë√∫ng
9. **Kh√¥ng validate edge cases** - Model fail ·ªü corner cases
10. **Kh√¥ng monitor production** - Performance degradation

---



---

# üìß PHASE 1: HI·ªÇU B√ÄI TO√ÅN - EMAIL THREAT DETECTION

---

## SLIDE 1: B√ÄI TO√ÅN C·ª§ TH·ªÇ

**T√™n d·ª± √°n:** Email Threat Detection System

**M√¥ t·∫£:** 
X√¢y d·ª±ng h·ªá th·ªëng AI t·ª± ƒë·ªông ph√¢n lo·∫°i email v√†o 5 categories:
- Legitimate (H·ª£p ph√°p)
- Spam (Th∆∞ r√°c)
- Phishing (L·ª´a ƒë·∫£o)
- Malware (Ch·ª©a m√£ ƒë·ªôc)
- BEC (Business Email Compromise)

**B·ªëi c·∫£nh:**
- C√¥ng ty nh·∫≠n 100,000 emails/ng√†y
- 30% l√† threats
- C·∫ßn ph√°t hi·ªán t·ª± ƒë·ªông trong <1 gi√¢y

---

## SLIDE 2: ‚úÖ 1.1 - X√ÅC ƒê·ªäNH LO·∫†I B√ÄI TO√ÅN

### **C√¢u h·ªèi:** ƒê√¢y l√† b√†i to√°n g√¨?

**Ph√¢n t√≠ch:**

**‚úÖ Classification** (Ph√¢n lo·∫°i)
- ƒê·∫ßu v√†o: Email (text + metadata)
- ƒê·∫ßu ra: 1 trong 5 categories
- C√≥ labeled data ƒë·ªÉ h·ªçc

**Lo·∫°i classification:**
- ‚úÖ **Multiclass Classification** (5 classes)
- ‚ùå Kh√¥ng ph·∫£i Binary (ch·ªâ c√≥ 2 classes)
- ‚ùå Kh√¥ng ph·∫£i Multilabel (1 email ch·ªâ thu·ªôc 1 class)
- ‚ùå Kh√¥ng ph·∫£i Regression (kh√¥ng d·ª± ƒëo√°n s·ªë)

---

## SLIDE 3: C√ÅC CLASS CHI TI·∫æT

| Class | Label | M√¥ t·∫£ | V√≠ d·ª• |
|-------|-------|-------|-------|
| **Legitimate** | 0 | Email c√¥ng vi·ªác b√¨nh th∆∞·ªùng | "Meeting at 3 PM" |
| **Spam** | 1 | Qu·∫£ng c√°o, marketing kh√¥ng mong mu·ªën | "Buy cheap viagra now!" |
| **Phishing** | 2 | Gi·∫£ m·∫°o ƒë·ªÉ ƒë√°nh c·∫Øp th√¥ng tin | "Verify your bank account" |
| **Malware** | 3 | Ch·ª©a attachment/link ƒë·ªôc h·∫°i | "Invoice.pdf" (malicious) |
| **BEC** | 4 | Gi·∫£ m·∫°o CEO/CFO y√™u c·∫ßu chuy·ªÉn ti·ªÅn | "CEO: Wire $50K urgently" |

---

## SLIDE 4: PH√ÇN BI·ªÜT C√ÅC LO·∫†I THREATS

### **Spam vs Phishing vs BEC**

**Spam:**
- M·ª•c ti√™u: Qu·∫£ng c√°o, b√°n h√†ng
- G·ª≠i h√†ng lo·∫°t (bulk)
- Kh√¥ng nh·∫Øm m·ª•c ti√™u c·ª• th·ªÉ
- √çt nguy hi·ªÉm (ch·ªâ l√†m phi·ªÅn)

**Phishing:**
- M·ª•c ti√™u: ƒê√°nh c·∫Øp credentials
- Gi·∫£ m·∫°o t·ªï ch·ª©c (bank, PayPal)
- C√≥ link gi·∫£ m·∫°o
- Nguy hi·ªÉm trung b√¨nh

**BEC:**
- M·ª•c ti√™u: L·ª´a chuy·ªÉn ti·ªÅn
- Gi·∫£ m·∫°o ng∆∞·ªùi trong c√¥ng ty (CEO, CFO)
- Nh·∫Øm m·ª•c ti√™u c·ª• th·ªÉ
- R·∫§T NGUY HI·ªÇM (loss trung b√¨nh $50K-$5M)

**Malware:**
- M·ª•c ti√™u: C√†i ƒë·∫∑t virus/ransomware
- C√≥ attachment ho·∫∑c link ƒë·ªôc h·∫°i
- C·ª±c k·ª≥ nguy hi·ªÉm

---

## SLIDE 5: V√ç D·ª§ C·ª§ TH·ªÇ T·ª™NG LO·∫†I

### **1. Legitimate Email**
```
From: john@company.com
To: team@company.com
Subject: Q4 Sales Report Ready

Hi Team,

The Q4 sales report has been finalized and uploaded 
to SharePoint. Please review by Friday.

Best regards,
John
```

**ƒê·∫∑c ƒëi·ªÉm:**
- From internal domain
- Business tone
- Clear purpose
- No urgency pressure
- No suspicious links

---

## SLIDE 6: V√ç D·ª§ - SPAM

### **2. Spam Email**
```
From: deals@bestoffers2024.com
To: you@company.com
Subject: üî• LOSE 20 LBS IN 2 WEEKS! LIMITED OFFER!

CONGRATULATIONS! You've been selected for our 
EXCLUSIVE weight loss program!

‚úÖ Lose weight FAST
‚úÖ No exercise needed
‚úÖ 100% natural ingredients

Click here NOW! Offer expires in 24 hours!
[SUSPICIOUS LINK]

Unsubscribe: [tiny link]
```

**ƒê·∫∑c ƒëi·ªÉm:**
- External, unknown sender
- Excessive punctuation (!!!)
- CAPITALS v√† emojis
- Too good to be true claims
- Generic greeting
- Unsubscribe link (but still unwanted)

---

## SLIDE 7: V√ç D·ª§ - PHISHING

### **3. Phishing Email**
```
From: security@paypa1.com  ‚Üê Ch√∫ √Ω: "1" thay "l"
To: victim@company.com
Subject: Urgent: Your PayPal Account Has Been Suspended

Dear Valued Customer,

We have detected unusual activity on your PayPal account.
For your security, we have SUSPENDED your account.

To restore access, please verify your information immediately:

[CLICK HERE TO VERIFY] ‚Üê Link gi·∫£: http://paypa1-verify.com

If you do not verify within 24 hours, your account will 
be permanently closed.

Thank you,
PayPal Security Team
```

**ƒê·∫∑c ƒëi·ªÉm:**
- Gi·∫£ m·∫°o sender (typosquatting: paypa1 vs paypal)
- Urgency + Fear tactics
- Request credentials
- Suspicious link domain
- Generic greeting "Dear Customer"
- Threat of account closure

---

## SLIDE 8: V√ç D·ª§ - MALWARE

### **4. Malware Delivery Email**
```
From: accounting@suspicious-domain.com
To: finance@company.com
Subject: Invoice #2024-10892

Dear Sir/Madam,

Please find attached the invoice for your recent order.

Payment is due within 7 days.

Attachment: Invoice_Oct_2024.pdf.exe  ‚Üê Nguy hi·ªÉm!

Regards,
Accounting Department
```

**ƒê·∫∑c ƒëi·ªÉm:**
- C√≥ attachment ƒë√°ng ng·ªù (.exe, .zip, .scr)
- Double extension (.pdf.exe)
- Generic content
- External sender pretending to be business
- No specific details about "order"
- Low IP reputation

---

## SLIDE 9: V√ç D·ª§ - BEC (Business Email Compromise)

### **5. BEC Email**
```
From: ceo@company.com  ‚Üê Email th·∫≠t ho·∫∑c spoofed
To: cfo@company.com
Subject: Urgent Wire Transfer Required

Hi Sarah,

I'm in a meeting with potential investors and we need 
to wire $80,000 immediately to secure the deal.

Please process this transfer ASAP:
Bank: [Details]
Account: [Number]
Reason: Investment deposit

This is time-sensitive and confidential. Don't mention 
this to anyone until I'm back.

Thanks,
Michael Chen
CEO
```

**ƒê·∫∑c ƒëi·ªÉm:**
- Gi·∫£ m·∫°o executive (CEO, CFO)
- Urgency + Confidentiality
- Request wire transfer
- Bypass normal approval process
- "Don't tell anyone"
- Time pressure
- Sophisticated language (kh√¥ng nh∆∞ spam)

---

## SLIDE 10: ‚úÖ 1.2 - X√ÅC ƒê·ªäNH SUCCESS METRICS

### **C√¢u h·ªèi:** Metric n√†o quan tr·ªçng nh·∫•t?

**Ph√¢n t√≠ch theo business impact:**

| Threat Type | Business Impact | Primary Metric |
|-------------|-----------------|----------------|
| Spam | Th·∫•p (ch·ªâ phi·ªÅn) | Precision |
| Phishing | Cao (m·∫•t credentials) | Recall |
| Malware | R·∫•t cao (ransomware) | Recall |
| BEC | C·ª±c cao ($50K-$5M loss) | Recall |

**K·∫øt lu·∫≠n:** 
- **Recall** quan tr·ªçng h∆°n Precision
- Kh√¥ng ƒë∆∞·ª£c b·ªè s√≥t threats (FN nguy hi·ªÉm!)
- Ch·∫•p nh·∫≠n m·ªôt s·ªë FP (block nh·∫ßm, c√≥ th·ªÉ recover)

---

## SLIDE 11: METRIC REQUIREMENTS C·ª§ TH·ªÇ

### **Minimum Acceptable Performance:**

**Overall:**
- Accuracy: >95%
- Macro F1-Score: >0.90

**Per-Class Requirements:**

| Class | Recall (Min) | Precision (Min) | L√Ω do |
|-------|-------------|-----------------|-------|
| Legitimate | 98% | 95% | Kh√¥ng block nh·∫ßm email quan tr·ªçng |
| Spam | 90% | 95% | OK n·∫øu b·ªè s√≥t m·ªôt s·ªë (√≠t nguy hi·ªÉm) |
| Phishing | 95% | 90% | KH√îNG ƒë∆∞·ª£c b·ªè s√≥t |
| Malware | 98% | 90% | TUY·ªÜT ƒê·ªêI kh√¥ng b·ªè s√≥t |
| BEC | 99% | 85% | ∆Øu ti√™n catch t·∫•t c·∫£, d√π c√≥ FP |

**Gi·∫£i th√≠ch:**
- BEC recall 99%: B·ªè s√≥t 1% = $50K-$5M loss!
- Legitimate precision 95%: Block nh·∫ßm 5% email = ch·∫•p nh·∫≠n ƒë∆∞·ª£c
- Spam recall 90%: B·ªè s√≥t 10% spam = OK, user c√≥ th·ªÉ delete manually

---

## SLIDE 12: CONFUSION MATRIX ANALYSIS

### **Cost Analysis:**

**False Positive (Lo·∫°i I Error):**
```
Legitimate ‚Üí Predicted as Threat
Cost: User annoyance, productivity loss
Severity: Medium
```

**False Negative (Lo·∫°i II Error):**
```
Spam ‚Üí Predicted as Legitimate: Low cost
Phishing ‚Üí Predicted as Legitimate: High cost
Malware ‚Üí Predicted as Legitimate: Very high cost
BEC ‚Üí Predicted as Legitimate: CRITICAL cost
```

**Trade-off Decision:**
‚Üí ∆Øu ti√™n **Recall** (catch threats) h∆°n **Precision** (avoid FP)
‚Üí Thi·∫øt l·∫≠p threshold ƒë·ªÉ favor Recall

---

## SLIDE 13: ‚úÖ 1.3 - THU TH·∫¨P Y√äU C·∫¶U H·ªÜ TH·ªêNG

### **Performance Requirements:**

**1. Inference Time:**
- Requirement: <1 second/email
- L√Ω do: Real-time filtering c·∫ßn nhanh
- Gi·ªõi h·∫°n: Kh√¥ng d√πng models qu√° ph·ª©c t·∫°p

**2. Model Size:**
- Requirement: <100 MB
- L√Ω do: Deploy tr√™n email server (limited memory)
- Gi·ªõi h·∫°n: Kh√¥ng d√πng deep learning n·∫∑ng

**3. Throughput:**
- Requirement: 100 emails/second
- L√Ω do: Peak time c√≥ th·ªÉ ƒë·∫øn 360K emails/hour
- Gi·∫£i ph√°p: C·∫ßn batch processing ho·∫∑c parallel

---

## SLIDE 14: Y√äU C·∫¶U H·ªÜ TH·ªêNG (tt)

### **4. Interpretability:**
- Requirement: HIGH
- L√Ω do: 
  - C·∫ßn gi·∫£i th√≠ch t·∫°i sao email b·ªã block
  - Compliance/audit requirements
  - User c√≥ th·ªÉ appeal decision
- Gi·ªõi h·∫°n: 
  - ∆Øu ti√™n: Logistic Regression, Tree-based
  - Tr√°nh: Black-box deep learning

**5. Update Frequency:**
- Requirement: Retrain weekly
- L√Ω do: Threats evolve rapidly
- C·∫ßn: Automated training pipeline

**6. Deployment:**
- Environment: On-premise email server
- OS: Linux (Ubuntu 20.04)
- Integration: SMTP gateway
- Fallback: Rule-based backup system

---

## SLIDE 15: Y√äU C·∫¶U COMPLIANCE & LEGAL

### **Privacy & Legal:**

**GDPR Compliance:**
- [ ] Kh√¥ng store email content l√¢u d√†i
- [ ] Ch·ªâ extract features c·∫ßn thi·∫øt
- [ ] C√≥ consent ƒë·ªÉ analyze emails
- [ ] Right to explanation (interpretability)

**Company Policy:**
- [ ] Kh√¥ng scan personal emails (ch·ªâ work emails)
- [ ] Log t·∫•t c·∫£ decisions ƒë·ªÉ audit
- [ ] C√≥ manual review process cho disputed cases
- [ ] Encrypt all data in transit v√† at rest

**Ethical Considerations:**
- [ ] False positives: C√≥ process ƒë·ªÉ unblock
- [ ] Transparency: User bi·∫øt email ƒë∆∞·ª£c scan
- [ ] No discrimination: Model kh√¥ng bias theo sender

---

## SLIDE 16: STAKEHOLDER REQUIREMENTS

### **C√°c b√™n li√™n quan:**

**1. End Users (Employees):**
- Mu·ªën: √çt false positives (kh√¥ng block nh·∫ßm)
- Mu·ªën: Interface ƒë·ªÉ report FP/FN
- Mu·ªën: Nhanh (kh√¥ng delay emails)

**2. IT Security Team:**
- Mu·ªën: High recall (catch all threats)
- Mu·ªën: Dashboard ƒë·ªÉ monitor
- Mu·ªën: Logs ƒë·ªÉ investigate incidents

**3. Management:**
- Mu·ªën: ROI positive (gi·∫£m losses t·ª´ BEC)
- Mu·ªën: Compliance ƒë·∫£m b·∫£o
- Mu·ªën: Low maintenance cost

**4. Legal/Compliance:**
- Mu·ªën: Audit trail ƒë·∫ßy ƒë·ªß
- Mu·ªën: GDPR compliant
- Mu·ªën: Explainable decisions

---

## SLIDE 17: T√ìM T·∫ÆT PHASE 1

### **‚úÖ Nh·ªØng g√¨ ƒë√£ x√°c ƒë·ªãnh:**

**1. Problem Type:**
- Multiclass Classification (5 classes)
- Supervised Learning
- Text + Metadata input

**2. Success Metrics:**
- Primary: Recall (per-class: 90-99%)
- Secondary: Precision (per-class: 85-95%)
- Overall: Accuracy >95%, Macro F1 >0.90

**3. Constraints:**
- Inference: <1 second/email
- Model size: <100 MB
- Interpretability: HIGH
- Throughput: 100 emails/second

**4. Compliance:**
- GDPR compliant
- Audit trail required
- Privacy-preserving

---

## SLIDE 18: DECISION SUMMARY TABLE

| Aspect | Decision | Rationale |
|--------|----------|-----------|
| **Problem Type** | Multiclass Classification (5 classes) | Clear categories, labeled data available |
| **Primary Metric** | Recall (weighted by severity) | Cost of FN >> Cost of FP in security |
| **Secondary Metric** | Precision, F1-Score | Balance needed for user experience |
| **Minimum Recall** | BEC: 99%, Malware: 98%, Phishing: 95%, Others: 90% | Based on financial impact |
| **Model Complexity** | Medium (not deep learning) | Interpretability + Speed requirements |
| **Update Cadence** | Weekly retraining | Threats evolve rapidly |
| **Deployment** | On-premise email gateway | Data privacy requirements |

---

## SLIDE 19: COMPARISON - EMAIL THREATS

### **ƒê·ªô nguy hi·ªÉm (Severity):**

```
Legitimate ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0% risk
    ‚Üì
Spam       ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10% risk (annoyance only)
    ‚Üì
Phishing   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 60% risk (credential theft)
    ‚Üì
Malware    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 80% risk (ransomware, data loss)
    ‚Üì
BEC        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100% risk (direct financial loss $50K-$5M)
```

**K·∫øt lu·∫≠n:**
‚Üí Model ph·∫£i t·∫≠p trung detect BEC > Malware > Phishing > Spam

---

## SLIDE 20: NEXT STEPS - PHASE 2

**Chu·∫©n b·ªã cho Phase 2 (Data Collection):**

**C·∫ßn thu th·∫≠p:**
- [ ] 50,000+ emails ƒë√£ labeled (10K/class)
- [ ] C√¢n b·∫±ng distribution ho·∫∑c c√≥ strategy cho imbalance
- [ ] Email headers (From, To, Subject, Date, Reply-To)
- [ ] Email body (text + HTML)
- [ ] Attachments info (filename, type, size)
- [ ] URLs trong email
- [ ] Metadata (IP sender, SPF/DKIM status)

**Sources:**
- Production email logs (with consent)
- Public datasets: Enron, SpamAssassin
- Honeypots ƒë·ªÉ catch threats
- User reports (manual labels)

---

## SLIDE 21: FEATURES PREVIEW (S·∫Ω DETAIL ·ªû PHASE 3)

**Categories c·ªßa features:**

**1. Sender Features:**
- Email domain reputation
- SPF/DKIM/DMARC pass/fail
- Sender trong company whitelist?
- Sender history (first time sender?)

**2. Content Features:**
- Subject line keywords
- Body text (TF-IDF, sentiment)
- Urgency words count
- Money amount mentions
- URL count v√† reputation
- Attachment presence & type

**3. Behavioral Features:**
- Time of send (work hours?)
- Reply patterns
- Email chain analysis

---

## SLIDE 22: EXPECTED CHALLENGES

**Challenges d·ª± ki·∫øn:**

**1. Imbalanced Data:**
- BEC r·∫•t hi·∫øm (~0.1% emails)
- Legitimate r·∫•t nhi·ªÅu (~70%)
- Solution: SMOTE, class weights, stratified split

**2. Evolving Threats:**
- Attackers thay ƒë·ªïi tactics li√™n t·ª•c
- Solution: Weekly retraining, continuous monitoring

**3. Sophisticated BEC:**
- R·∫•t gi·ªëng legitimate emails
- Language professional, no obvious red flags
- Solution: Behavioral features, executive impersonation detection

**4. False Positives Impact:**
- Block nh·∫ßm legitimate emails = serious
- Solution: Lower threshold, manual review queue

---

## SLIDE 23: RISK MITIGATION

**Risk Management:**

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| High FP rate | High | Medium | Lower threshold, A/B testing |
| Miss critical BEC | Critical | Low | Prioritize recall, manual review for high-value targets |
| Model drift | High | High | Weekly retraining, performance monitoring |
| Adversarial attacks | Medium | Medium | Ensemble models, anomaly detection backup |
| Privacy violation | Critical | Low | Strict data governance, compliance checks |

---

## SLIDE 24: SUCCESS CRITERIA CHECKLIST

**Project s·∫Ω th√†nh c√¥ng n·∫øu:**

- [ ] Overall accuracy >95%
- [ ] BEC recall ‚â•99% (b·ªè s√≥t <1%)
- [ ] Malware recall ‚â•98%
- [ ] Phishing recall ‚â•95%
- [ ] Legitimate precision ‚â•95% (FP <5%)
- [ ] Inference time <1s per email
- [ ] Model size <100MB
- [ ] Can explain any decision (interpretability)
- [ ] GDPR compliant
- [ ] ROI positive (losses prevented > system cost)

---

## SLIDE 25: PHASE 1 DELIVERABLES

**Documents ƒë√£ ho√†n th√†nh:**

‚úÖ **Problem Definition Document:**
- Problem type: Multiclass classification
- 5 classes defined with examples
- Use cases v√† business context

‚úÖ **Metrics Requirement Document:**
- Primary: Recall (per-class thresholds)
- Secondary: Precision, F1, Accuracy
- Business justification cho t·ª´ng metric

‚úÖ **System Requirements Document:**
- Performance: <1s inference, 100 emails/sec
- Model constraints: <100MB, interpretable
- Deployment: On-premise, Linux
- Compliance: GDPR, audit trail

‚úÖ **Stakeholder Sign-off:**
- Requirements approved by IT Security, Legal, Management

---

## SLIDE 26: APPROVAL CHECKLIST

**Tr∆∞·ªõc khi proceed to Phase 2:**

**Technical Approval:**
- [ ] Data Science Lead: Metrics achievable?
- [ ] ML Engineer: Technical constraints realistic?
- [ ] Security Team: Requirements comprehensive?

**Business Approval:**
- [ ] IT Director: Budget approved?
- [ ] Legal: Compliance requirements clear?
- [ ] CFO: ROI projection acceptable?

**Risk Assessment:**
- [ ] Risk register reviewed
- [ ] Mitigation strategies approved
- [ ] Fallback plan documented

**‚Üí ALL APPROVED? Proceed to Phase 2! üöÄ**

---

## SLIDE 27: T√ìM T·∫ÆT - PHASE 1 COMPLETE

**Phase 1: Hi·ªÉu B√†i To√°n ‚úÖ**

```
‚úÖ 1.1 X√°c ƒë·ªãnh lo·∫°i: Multiclass Classification (5 classes)
‚úÖ 1.2 Success Metrics: Recall-focused, per-class thresholds
‚úÖ 1.3 System Requirements: Speed, size, interpretability
‚úÖ Stakeholder alignment: All parties agree
‚úÖ Risk assessment: Identified & mitigated
‚úÖ Go/No-Go decision: GO! üöÄ
```

**Next Phase 2: Data Collection & EDA**
- Thu th·∫≠p 50K+ labeled emails
- Analyze distribution
- Check data quality
- Identify challenges

---

## SLIDE 28: B√ÄI T·∫¨P

**Exercise: Apply Phase 1 to Your Problem**

Ch·ªçn 1 trong c√°c b√†i to√°n sau v√† complete Phase 1:

**Option 1: Credit Card Fraud Detection**
- Binary classification
- Highly imbalanced (0.1% fraud)
- Real-time requirement

**Option 2: Customer Churn Prediction**
- Binary classification
- Balanced data
- Interpretability critical

**Option 3: Product Review Sentiment**
- Multiclass (5 stars)
- Large dataset available
- Speed not critical

**Y√™u c·∫ßu:** Complete slides 10-16 template for your chosen problem

---



---

# üìä PHASE 1: HI·ªÇU B√ÄI TO√ÅN - MALWARE THREAT DETECTION WITH AI

---

## SLIDE 1: MODULE 5 OVERVIEW

**Welcome to Module 5: Advanced Malware Analysis**

**Focus Areas:**
- AI-driven detection techniques
- Modern malware classification
- Real-time threat response

**Duration:** Comprehensive deep-dive session

**Learning Outcomes:**
- Master modern malware detection
- Build ML models for threat classification
- Deploy production-ready systems

---

## SLIDE 2: B√ÄI TO√ÅN TH·ª∞C T·∫æ

**T√¨nh hu·ªëng:**
B·∫°n l√† Security Analyst t·∫°i c√¥ng ty antivirus

**Th·ª±c tr·∫°ng h√†ng ng√†y:**
- 450,000+ malware m·∫´u m·ªõi m·ªói ng√†y
- Signature-based detection b·ªã bypass b·ªüi polymorphic malware
- Zero-day malware kh√¥ng c√≥ signature
- Ph√¢n t√≠ch th·ªß c√¥ng: 1-2 samples/gi·ªù
- C·∫ßn: Ph√¢n t√≠ch h√†ng ngh√¨n samples/gi·ªù

**Th√°ch th·ª©c:**
‚Üí L√†m th·∫ø n√†o ph√°t hi·ªán malware ch∆∞a t·ª´ng th·∫•y?

---

## SLIDE 3: PHASE 1.1 - X√ÅC ƒê·ªäNH LO·∫†I B√ÄI TO√ÅN

**C√¢u h·ªèi 1: ƒê√¢y l√† lo·∫°i b√†i to√°n g√¨?**

**Ph√¢n t√≠ch:**
- Input: File executable (.exe, .dll, .apk)
- Output: Malware hay Benign?
- C√≥ label s·∫µn (malware/benign)
- 2 classes

**‚Üí ƒê√¢y l√† b√†i to√°n BINARY CLASSIFICATION**

---

## SLIDE 4: T·∫†I SAO L√Ä BINARY CLASSIFICATION?

**Binary Classification nghƒ©a l√†:**
- Ch·ªâ c√≥ 2 classes (categories)
- Class 0: Benign (file an to√†n)
- Class 1: Malware (file ƒë·ªôc h·∫°i)

**So s√°nh v·ªõi c√°c lo·∫°i kh√°c:**
```
Binary:      Malware vs Benign
Multiclass:  Trojan vs Worm vs Virus vs Ransomware
Regression:  D·ª± ƒëo√°n risk score (0-100)
Clustering:  Nh√≥m malware c√≥ h√†nh vi t∆∞∆°ng t·ª±
```

**‚Üí Lab n√†y: Binary Classification**

---

## SLIDE 5: N√Çng CAO - MULTICLASS CLASSIFICATION

**N·∫øu mu·ªën ph√¢n lo·∫°i chi ti·∫øt h∆°n:**

**Multiclass Problem:**
- Class 0: Benign
- Class 1: Trojan
- Class 2: Worm
- Class 3: Virus
- Class 4: Ransomware
- Class 5: Rootkit
- Class 6: Spyware

**Kh√°c bi·ªát:**
- Model ph·ª©c t·∫°p h∆°n
- C·∫ßn nhi·ªÅu data h∆°n m·ªói class
- Harder to achieve high accuracy

---

## SLIDE 6: PHASE 1.2 - X√ÅC ƒê·ªäNH SUCCESS METRICS

**C√¢u h·ªèi 2: L√†m sao bi·∫øt model "t·ªët"?**

**Kh√¥ng ch·ªâ l√† Accuracy!**

V·ªõi antivirus, c·∫ßn c√¢n nh·∫Øc:
- False Positive (FP): File t·ªët b·ªã nh·∫≠n nh·∫ßm l√† malware
- False Negative (FN): Malware b·ªã b·ªè s√≥t

**‚Üí C·∫ßn ƒë·ªãnh nghƒ©a r√µ success metrics**

---

## SLIDE 7: HI·ªÇU FALSE POSITIVE V√Ä FALSE NEGATIVE

**False Positive (Type I Error):**
```
Truth: File AN TO√ÄN
Model d·ª± ƒëo√°n: MALWARE
H·∫≠u qu·∫£: 
- User kh√¥ng d√πng ƒë∆∞·ª£c software h·ª£p ph√°p
- M·∫•t l√≤ng tin v√†o antivirus
- T·ªën th·ªùi gian whitelist
```

**False Negative (Type II Error):**
```
Truth: MALWARE
Model d·ª± ƒëo√°n: An to√†n
H·∫≠u qu·∫£:
- Malware v√†o ƒë∆∞·ª£c h·ªá th·ªëng
- Data b·ªã ƒë√°nh c·∫Øp
- Ransomware m√£ h√≥a files
- ‚òÖ NGUY HI·ªÇM H∆†N!
```

---

## SLIDE 8: CH·ªåN METRICS CHO ANTIVIRUS

**Trong antivirus: False Negative nguy hi·ªÉm h∆°n!**

**Priority Metrics (Theo th·ª© t·ª±):**

1. **Recall (Sensitivity)** - Cao nh·∫•t!
   - "Trong t·∫•t c·∫£ malware th·∫≠t, b·∫Øt ƒë∆∞·ª£c bao nhi√™u?"
   - Target: >95% (b·ªè s√≥t <5%)

2. **Precision**
   - "Trong c√°c d·ª± ƒëo√°n malware, ƒë√∫ng bao nhi√™u?"
   - Target: >90% (ch·∫•p nh·∫≠n 10% FP)

3. **F1-Score**
   - C√¢n b·∫±ng Precision v√† Recall
   - Target: >0.92

4. **Accuracy**
   - T·ªïng quan
   - Target: >93%

---

## SLIDE 9: C√îNG TH·ª®C METRICS

**Confusion Matrix:**
```
                Predicted
              Benign  Malware
Actual Benign   TN      FP
       Malware  FN      TP
```

**Formulas:**
```
Accuracy  = (TP + TN) / (TP + TN + FP + FN)
Precision = TP / (TP + FP)
Recall    = TP / (TP + FN)  ‚Üê Quan tr·ªçng nh·∫•t!
F1-Score  = 2 √ó (Precision √ó Recall) / (Precision + Recall)
```

---

## SLIDE 10: V√ç D·ª§ T√çNH METRICS

**Scenario:** Test tr√™n 1000 files
```
True Benign: 700 files
True Malware: 300 files

Model predictions:
- Detected correctly as Benign: 680 (TN)
- Benign wrongly as Malware: 20 (FP)
- Malware wrongly as Benign: 10 (FN) ‚Üê Nguy hi·ªÉm!
- Detected correctly as Malware: 290 (TP)
```

**Confusion Matrix:**
```
        Benign  Malware
Benign    680     20
Malware    10    290
```

---

## SLIDE 11: T√çNH TO√ÅN K·∫æT QU·∫¢

**T·ª´ confusion matrix tr∆∞·ªõc:**

```
Accuracy  = (680 + 290) / 1000 = 97.0%
Precision = 290 / (290 + 20) = 93.5%
Recall    = 290 / (290 + 10) = 96.7% ‚òÖ
F1-Score  = 2 √ó (0.935 √ó 0.967) / (0.935 + 0.967) = 0.951
```

**ƒê√°nh gi√°:**
- ‚úÖ Recall 96.7% ‚Üí T·ªët! Ch·ªâ b·ªè s√≥t 10/300 malware
- ‚úÖ Precision 93.5% ‚Üí OK, ch·∫•p nh·∫≠n 20 FP
- ‚úÖ F1 0.951 ‚Üí Excellent
- ‚úÖ Model ƒë·∫°t y√™u c·∫ßu!

---

## SLIDE 12: TARGET METRICS CHO PROJECT

**Minimum Requirements:**

| Metric | Target | L√Ω do |
|--------|--------|-------|
| **Recall** | **‚â• 95%** | Kh√¥ng ƒë∆∞·ª£c b·ªè s√≥t >5% malware |
| Precision | ‚â• 90% | Ch·∫•p nh·∫≠n ‚â§10% false alarms |
| F1-Score | ‚â• 0.92 | C√¢n b·∫±ng t·ªët |
| Accuracy | ‚â• 93% | T·ªïng quan |

**Stretch Goals (L√Ω t∆∞·ªüng):**
- Recall: 98%
- Precision: 95%
- F1: 0.96

---

## SLIDE 13: PHASE 1.3 - Y√äU C·∫¶U V·ªÄ T·ªêC ƒê·ªò

**C√¢u h·ªèi 3: Model ph·∫£i nhanh nh∆∞ th·∫ø n√†o?**

**Real-time Scanning Requirements:**
- User scan 1 file: K·∫øt qu·∫£ trong <1 gi√¢y
- Background scan: 1000+ files/ph√∫t
- On-access scan: <100ms (kh√¥ng l√†m ch·∫≠m system)

**Training Time:**
- C√≥ th·ªÉ l√¢u (v√†i gi·ªù ƒë·∫øn v√†i ng√†y)
- Ch·ªâ train 1 l·∫ßn, d√πng l·∫°i nhi·ªÅu l·∫ßn

**‚Üí Inference speed quan tr·ªçng h∆°n training speed!**

---

## SLIDE 14: Y√äU C·∫¶U MODEL SIZE

**Deployment Constraints:**

**Desktop Antivirus:**
- Model size: <100 MB
- RAM usage: <500 MB
- CPU only (kh√¥ng c√≥ GPU)

**Mobile Antivirus:**
- Model size: <10 MB
- RAM usage: <100 MB
- Battery friendly

**Cloud-based:**
- Model size: Kh√¥ng gi·ªõi h·∫°n
- C√≥ GPU
- Nh∆∞ng c·∫ßn internet

**‚Üí Lab n√†y: Desktop deployment**

---

## SLIDE 15: Y√äU C·∫¶U V·ªÄ INTERPRETABILITY

**C√¢u h·ªèi 4: C·∫ßn gi·∫£i th√≠ch ƒë∆∞·ª£c kh√¥ng?**

**Hai tr∆∞·ªùng ph√°i:**

**Black-box Models (Deep Learning):**
- ‚úÖ Accuracy cao h∆°n
- ‚ùå Kh√¥ng gi·∫£i th√≠ch ƒë∆∞·ª£c
- ‚ùå Kh√≥ debug

**Interpretable Models (Traditional ML):**
- ‚úÖ Hi·ªÉu ƒë∆∞·ª£c t·∫°i sao d·ª± ƒëo√°n v·∫≠y
- ‚úÖ D·ªÖ debug
- ‚úÖ User tin t∆∞·ªüng h∆°n
- ‚ùå Accuracy c√≥ th·ªÉ th·∫•p h∆°n m·ªôt ch√∫t

**‚Üí Lab n√†y: Traditional ML (interpretable)**

---

## SLIDE 16: T·∫†I SAO C·∫¶N INTERPRETABILITY?

**Use Cases c·∫ßn gi·∫£i th√≠ch:**

**1. Security Analyst Review:**
```
File: suspicious.exe
Prediction: MALWARE (95% confidence)
Reasons:
- Packs code with UPX
- Modifies registry keys
- Makes network connections to unknown IPs
- High entropy section (encrypted code)
```

**2. False Positive Analysis:**
```
File: legitimate.exe (Office Software)
Prediction: MALWARE (60% confidence)
Why wrong:
- Legitimate code packer
- Normal registry access
‚Üí Add to whitelist
```

---

## SLIDE 17: DEPLOYMENT ENVIRONMENT

**C√¢u h·ªèi 5: Model s·∫Ω ch·∫°y ·ªü ƒë√¢u?**

**3 Options:**

**Option 1: On-device (Endpoint)**
- ‚úÖ Offline, kh√¥ng c·∫ßn internet
- ‚úÖ Fast, low latency
- ‚úÖ Privacy (data kh√¥ng r·ªùi m√°y)
- ‚ùå Limited resources

**Option 2: Cloud-based**
- ‚úÖ Powerful, c√≥ GPU
- ‚úÖ D·ªÖ update model
- ‚ùå C·∫ßn internet
- ‚ùå Latency cao

**Option 3: Hybrid**
- Light model on-device
- Heavy analysis in cloud

**‚Üí Lab n√†y: On-device (endpoint)**

---

## SLIDE 18: T√ìM T·∫ÆT B√ÄI TO√ÅN

**B√†i to√°n ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a r√µ:**

```
Problem Type: Binary Classification
Classes: 
  - 0 = Benign (safe files)
  - 1 = Malware (malicious files)

Success Metrics:
  - Recall ‚â• 95% (priority #1)
  - Precision ‚â• 90%
  - F1-Score ‚â• 0.92
  - Accuracy ‚â• 93%

Performance Requirements:
  - Inference: <1 second per file
  - Model size: <100 MB
  - CPU only (no GPU)

Deployment: Desktop endpoint
Interpretability: High (need explanations)
```

---

## SLIDE 19: INPUT V√Ä OUTPUT

**INPUT: Executable File**
```
File types:
- Windows: .exe, .dll, .sys
- Android: .apk, .dex
- Linux: ELF binaries
- Scripts: .ps1, .bat, .sh

Typical size: 100 KB - 10 MB
```

**OUTPUT: Classification + Confidence**
```
{
  "prediction": "malware",
  "confidence": 0.95,
  "risk_level": "high",
  "detected_behaviors": [...]
}
```

---

## SLIDE 20: BUSINESS CONTEXT

**Stakeholders:**

**1. End Users**
- Mu·ªën: B·∫£o v·ªá t·ªët, √≠t false positive
- KPI: User satisfaction score

**2. Security Team**
- Mu·ªën: Detect rate cao, analysis tools
- KPI: Malware catch rate

**3. Product Team**
- Mu·ªën: Fast, small size, easy deploy
- KPI: System performance

**4. Business**
- Mu·ªën: Cost-effective, scalable
- KPI: Cost per detection, ROI

---

## SLIDE 21: COST ANALYSIS

**Cost c·ªßa False Positive:**
- Support ticket: $50
- User frustration
- Potential churn
- Whitelist maintenance

**Cost c·ªßa False Negative:**
- Data breach: $4.35M average
- Ransomware damage: $1.85M average
- Reputation loss
- Legal liability

**‚Üí FN cost >> FP cost (h√†ng ngh√¨n l·∫ßn!)**
**‚Üí ∆Øu ti√™n Recall cao!**

---

## SLIDE 22: CONSTRAINTS V√Ä ASSUMPTIONS

**Technical Constraints:**
- Ch·ªâ c√≥ file binary (kh√¥ng c√≥ source code)
- Kh√¥ng th·ªÉ execute file (sandbox limit)
- Static analysis only
- Limited compute resources

**Assumptions:**
- File format valid (kh√¥ng corrupt)
- C√≥ th·ªÉ extract features
- Labels reliable (dataset quality)
- Malware behaviors stable (kh√¥ng thay ƒë·ªïi qu√° nhanh)

---

## SLIDE 23: SUCCESS CRITERIA - CHI TI·∫æT

**ƒê·ªãnh nghƒ©a "Success" r√µ r√†ng:**

**Phase 1: Development (Lab)**
- Recall ‚â• 95% tr√™n test set
- F1-Score ‚â• 0.92
- Model trains trong <30 ph√∫t
- Inference <1s per file

**Phase 2: Production (Real-world)**
- Maintain 95% recall for 90 days
- False positive rate <1% daily
- 99.9% uptime
- Handle 10K files/hour

---

## SLIDE 24: OUT OF SCOPE

**Nh·ªØng g√¨ KH√îNG l√†m trong lab n√†y:**

‚ùå Dynamic analysis (kh√¥ng ch·∫°y malware)
‚ùå Sandbox environment
‚ùå Network behavior analysis
‚ùå Real-time monitoring
‚ùå Automatic malware removal
‚ùå Cross-platform support (ch·ªâ focus 1 platform)
‚ùå Production deployment pipeline

**‚Üí Focus: Core ML model for static analysis**

---

## SLIDE 25: RELATED PROBLEMS

**B√†i to√°n t∆∞∆°ng t·ª±:**

**Spam Detection:**
- Binary classification
- Text analysis
- Similar metrics priority

**Fraud Detection:**
- Imbalanced data
- High cost of FN
- Real-time requirements

**Intrusion Detection:**
- Anomaly detection
- Network traffic analysis
- Same security domain

**‚Üí Techniques c√≥ th·ªÉ t√°i s·ª≠ d·ª•ng!**

---

## SLIDE 26: BASELINE COMPARISON

**So v·ªõi existing solutions:**

**Signature-based Antivirus:**
- Detection rate: 70-80%
- False positive: <0.1%
- Speed: Very fast
- ‚ùå Miss zero-day malware

**Behavioral Analysis:**
- Detection rate: 85-90%
- False positive: 5-10%
- Speed: Slow
- ‚ùå Need execution

**Our ML Approach (Target):**
- Detection rate: 95%+
- False positive: 1-2%
- Speed: Fast
- ‚úÖ Detect unknown malware

---

## SLIDE 27: DATA REQUIREMENTS PREVIEW

**C·∫ßn bao nhi√™u data?**

**Minimum:**
- 1,000 samples (500 benign + 500 malware)
- 10-50 samples per feature

**Good:**
- 10,000 samples (7,000 benign + 3,000 malware)
- Cover multiple malware families

**Ideal:**
- 100,000+ samples
- Balanced across families
- Recent samples (<1 year old)

**‚Üí Lab n√†y: 10,000 samples**

---

## SLIDE 28: FEATURE TYPES PREVIEW

**C·∫ßn extract features g√¨ t·ª´ malware?**

**Static Features:**
- File properties (size, entropy, headers)
- PE structure (sections, imports, exports)
- String patterns (URLs, IPs, registry keys)
- Code characteristics (opcodes, API calls)

**‚Üí Chi ti·∫øt ·ªü Phase 2 (Feature Engineering)**

---

## SLIDE 29: TIMELINE ESTIMATION

**Project Timeline:**

```
Week 1: Data collection & EDA (2-3 days)
Week 2: Feature engineering (3-4 days)
Week 3: Model training & selection (2-3 days)
Week 4: Evaluation & tuning (2-3 days)
Week 5: Documentation & presentation (1-2 days)

Total: 4-5 weeks for complete project
Lab: 2-3 sessions (6-9 hours)
```

---

## SLIDE 30: RISK ANALYSIS

**Potential Risks:**

**Technical Risks:**
- Imbalanced dataset ‚Üí Use stratification, class weights
- Feature extraction errors ‚Üí Robust parsing
- Model overfitting ‚Üí Cross-validation, regularization
- New malware families ‚Üí Regular retraining

**Business Risks:**
- High false positive ‚Üí Careful threshold tuning
- Slow inference ‚Üí Model optimization
- Large model size ‚Üí Compression techniques

---

## SLIDE 31: ETHICAL CONSIDERATIONS

**Ethics trong Malware Detection:**

**Privacy:**
- ‚úÖ Analyze file structure only
- ‚ùå Kh√¥ng scan user documents
- ‚úÖ Local processing (no cloud upload)

**Bias:**
- Avoid bias against:
  - Legitimate crackers/debuggers
  - Open-source tools
  - Security research tools

**Transparency:**
- Clear v·ªÅ false positive possibility
- Give users override option
- Explain detections

---

## SLIDE 32: REGULATORY COMPLIANCE

**Compliance Requirements:**

**GDPR (EU):**
- Data minimization
- User consent
- Right to explanation

**CCPA (California):**
- Privacy notice
- User rights

**Industry Standards:**
- AMTSO (Anti-Malware Testing Standards)
- Common Criteria certification

---

## SLIDE 33: COMPETITIVE LANDSCAPE

**Existing Solutions:**

| Product | Detection Rate | FP Rate | Method |
|---------|----------------|---------|--------|
| Vendor A | 95% | 0.5% | Signature + Cloud |
| Vendor B | 92% | 1.0% | Behavioral |
| Vendor C | 88% | 0.3% | Signature only |
| **Our Target** | **95%** | **1-2%** | **ML-based** |

**Differentiation: Balance accuracy v·ªõi low FP**

---

## SLIDE 34: USER PERSONAS

**Who will use this?**

**Persona 1: Home User**
- Needs: Easy to use, no false alarms
- Priority: Don't block legitimate software
- Tech level: Low

**Persona 2: Enterprise IT Admin**
- Needs: Detailed reports, configurability
- Priority: Catch all threats
- Tech level: High

**Persona 3: Security Researcher**
- Needs: Explainability, analysis tools
- Priority: Understand detections
- Tech level: Expert

---

## SLIDE 35: CHECKLIST - PHASE 1 HO√ÄN TH√ÄNH

**‚úÖ ƒê√£ x√°c ƒë·ªãnh:**

- [x] Problem type: Binary Classification
- [x] Classes: Benign (0) vs Malware (1)
- [x] Success metrics: Recall ‚â•95%, Precision ‚â•90%, F1 ‚â•0.92
- [x] Performance: <1s inference, <100MB model
- [x] Deployment: Desktop endpoint
- [x] Interpretability: High (need explanations)
- [x] Stakeholders: Users, Security, Product, Business
- [x] Constraints: Static analysis, no execution
- [x] Risks identified v√† mitigation plans
- [x] Timeline: 4-5 weeks / 2-3 lab sessions

---

## SLIDE 36: C√ÇNH B√ÅO TH∆Ø·ªúNG G·∫∂P

**Common Mistakes trong Phase 1:**

‚ùå Ch·ªâ nh√¨n Accuracy
‚Üí ‚úÖ Focus v√†o Recall cho security

‚ùå Ignore inference speed
‚Üí ‚úÖ Set clear performance targets

‚ùå Kh√¥ng x√°c ƒë·ªãnh deployment environment
‚Üí ‚úÖ Bi·∫øt model ch·∫°y ·ªü ƒë√¢u

‚ùå Vague success criteria
‚Üí ‚úÖ S·ªë li·ªáu c·ª• th·ªÉ (‚â•95% recall)

‚ùå Kh√¥ng t√≠nh business cost
‚Üí ‚úÖ Hi·ªÉu FN cost >> FP cost

---

## SLIDE 37: B√ÄI T·∫¨P T∆Ø DUY

**C√¢u h·ªèi 1:**
N·∫øu model c√≥ Recall=99% v√† Precision=50%, b·∫°n c√≥ deploy kh√¥ng? T·∫°i sao?

**C√¢u h·ªèi 2:**
L√†m th·∫ø n√†o ƒë·ªÉ gi·∫£m False Positive m√† kh√¥ng l√†m gi·∫£m Recall?

**C√¢u h·ªèi 3:**
N·∫øu ph√°t hi·ªán malware m·ªõi m·ªói ng√†y tƒÉng 50%, strategy n√†o ƒë·ªÉ model v·∫´n effective?

---

## SLIDE 38: ƒê√ÅP √ÅN B√ÄI T·∫¨P

**C√¢u 1: Recall=99%, Precision=50%**
```
Ph√¢n t√≠ch:
- B·∫Øt ƒë∆∞·ª£c 99% malware ‚úÖ
- Nh∆∞ng 50% detections l√† false alarms ‚ùå
- 1000 detections ‚Üí 500 l√† FP
- User s·∫Ω r·∫•t phi·ªÅn!

Decision: KH√îNG deploy production
‚Üí C·∫ßn balance t·ªët h∆°n (min Precision 90%)
```

---

## SLIDE 39: ƒê√ÅP √ÅN B√ÄI T·∫¨P (tt)

**C√¢u 2: Gi·∫£m FP m√† gi·ªØ Recall**

**Strategies:**
- Adjust classification threshold
- Add whitelisting cho known-good software
- Combine multiple models (ensemble)
- Feature engineering t·ªët h∆°n
- More training data cho benign samples
- Post-processing rules

---

## SLIDE 40: ƒê√ÅP √ÅN B√ÄI T·∫¨P (tt)

**C√¢u 3: Malware tƒÉng 50%/ng√†y**

**Strategies:**
- Active learning: Prioritize labeling new samples
- Online learning: Update model incrementally
- Anomaly detection: Catch unknown patterns
- Regular retraining: Weekly ‚Üí Daily
- Community threat intelligence feeds
- Automated labeling pipeline

---

## SLIDE 41: PHASE 1 ‚Üí PHASE 2 TRANSITION

**ƒê√£ ho√†n th√†nh Phase 1:**
‚úÖ Hi·ªÉu r√µ b√†i to√°n
‚úÖ ƒê·ªãnh nghƒ©a success metrics
‚úÖ X√°c ƒë·ªãnh constraints

**Ti·∫øp theo - Phase 2: Data Collection**
- T√¨m ngu·ªìn malware samples
- Build dataset v·ªõi labels
- Exploratory Data Analysis
- Feature extraction planning

**Preview: S·∫Ω c·∫ßn ~10,000 samples!**

---

## SLIDE 42: T√ÄI LI·ªÜU THAM KH·∫¢O

**Papers:**
- "Deep Learning for Malware Detection" (IEEE 2019)
- "Static Malware Analysis Using Machine Learning Methods" (2020)

**Datasets:**
- VirusShare (millions of samples)
- MalwareBazaar
- EMBER dataset

**Tools:**
- PEiD - PE analysis
- radare2 - Reverse engineering
- YARA - Pattern matching

---

## SLIDE 43: INDUSTRY BENCHMARKS

**State-of-the-art (SOTA) Results:**

| Approach | Dataset | Accuracy | Recall | Precision |
|----------|---------|----------|--------|-----------|
| CNN | EMBER | 96.5% | 95.8% | 97.2% |
| Random Forest | Custom | 95.2% | 94.5% | 95.9% |
| XGBoost | VirusTotal | 97.1% | 96.5% | 97.7% |
| Ensemble | EMBER | 98.2% | 97.8% | 98.5% |

**Our Target: Competitive v·ªõi Random Forest**

---

## SLIDE 44: LEARNING RESOURCES

**ƒê·ªÉ hi·ªÉu s√¢u h∆°n:**

**Courses:**
- Malware Analysis Course (Practical Malware Analysis book)
- Machine Learning for Security (Coursera)

**Blogs:**
- Malwarebytes Labs
- Kaspersky Threatpost
- FireEye Blog

**Communities:**
- r/malware (Reddit)
- MalwareTech forum
- VirusTotal community

---

## SLIDE 45: SUMMARY - PHASE 1 COMPLETED

**ƒê√£ h·ªçc ƒë∆∞·ª£c g√¨:**
- ‚úÖ Binary Classification problem
- ‚úÖ Recall l√† metric quan tr·ªçng nh·∫•t
- ‚úÖ Balance Precision v√† Recall
- ‚úÖ Inference speed matters
- ‚úÖ Interpretability valuable
- ‚úÖ FN cost >> FP cost
- ‚úÖ Deployment constraints matter

**Key Takeaway:**
> "Trong security, KH√îNG B·ªé S√ìT (Recall) quan tr·ªçng h∆°n KH√îNG B√ÅO ƒê·ªòNG GI·∫¢ (Precision), nh∆∞ng c·∫ßn balance!"

---

## SLIDE 46: NEXT SESSION PREVIEW

**Session ti·∫øp theo: Phase 2 - Data Collection & EDA**

**N·ªôi dung:**
- Thu th·∫≠p malware samples
- Labeling strategy
- Dataset quality checks
- Exploratory Data Analysis
- Feature extraction planning

**Chu·∫©n b·ªã:**
- ƒê·ªçc v·ªÅ PE file format
- Install analysis tools
- Review dataset sources

---

## SLIDE 47: B√ÄI T·∫¨P V·ªÄ NH√Ä

**B√†i 1: Research (B·∫Øt bu·ªôc)**
T√¨m hi·ªÉu 3 malware families g·∫ßn ƒë√¢y:
- T√™n malware
- C√°ch l√¢y nhi·ªÖm
- H√†nh vi ch√≠nh
- L√†m sao detect

**B√†i 2: Metrics Calculation (B·∫Øt bu·ªôc)**
Cho confusion matrix, t√≠nh t·∫•t c·∫£ metrics v√† quy·∫øt ƒë·ªãnh deploy hay kh√¥ng

**B√†i 3: Tool Exploration (Optional)**
C√†i ƒë·∫∑t v√† th·ª≠ PE analysis tools

---

## SLIDE 48: THANK YOU!

**C√¢u h·ªèi?**

**Next Session:**
- Date: [Ng√†y]
- Time: [Gi·ªù]
- Topic: Data Collection & Feature Engineering

**Contact:**
- Email: [email]
- Slack: #malware-detection-lab

**H·∫πn g·∫∑p l·∫°i!** üõ°Ô∏è

---


---


# üìä PHASE 1: HI·ªÇU B√ÄI TO√ÅN - NETWORK ANOMALY DETECTION

## Slides Text cho Module 6

---

## SLIDE 1: PHASE 1 OVERVIEW

**HI·ªÇU B√ÄI TO√ÅN - 5 B∆Ø·ªöC QUAN TR·ªåNG**

```
Phase 1: Problem Understanding
‚îú‚îÄ B∆∞·ªõc 1.1: X√°c ƒë·ªãnh lo·∫°i b√†i to√°n ML
‚îú‚îÄ B∆∞·ªõc 1.2: X√°c ƒë·ªãnh success metrics
‚îú‚îÄ B∆∞·ªõc 1.3: Thu th·∫≠p y√™u c·∫ßu k·ªπ thu·∫≠t
‚îú‚îÄ B∆∞·ªõc 1.4: Ph√¢n t√≠ch business context
‚îî‚îÄ B∆∞·ªõc 1.5: Document to√†n b·ªô requirements
```

**Th·ªùi gian:** 2-4 gi·ªù (kh√¥ng b·ªè qua!)

**T·∫°i sao quan tr·ªçng:** 
- Hi·ªÉu sai b√†i to√°n ‚Üí L√†m sai h·∫øt
- Ch·ªçn sai metrics ‚Üí Model "t·ªët" nh∆∞ng v√¥ d·ª•ng
- Thi·∫øu requirements ‚Üí Deploy th·∫•t b·∫°i

---

## SLIDE 2: T√åNH HU·ªêNG TH·ª∞C T·∫æ

**B·∫°n l√† Security Engineer t·∫°i ng√¢n h√†ng ABC**

**Email t·ª´ CTO:**
```
Subject: Urgent - Need AI for Network Security

Ch√∫ng ta ƒëang c√≥ v·∫•n ƒë·ªÅ v·ªõi network security.
M·ªói ng√†y c√≥ h√†ng tri·ªáu network events, team SOC
kh√¥ng th·ªÉ theo d√µi h·∫øt. C·∫ßn AI gi√∫p ph√°t hi·ªán
c√°c anomalies t·ª± ƒë·ªông.

Deadline: 2 th√°ng
Budget: 50,000 USD

C√≥ l√†m ƒë∆∞·ª£c kh√¥ng?
```

**C√¢u h·ªèi:** B·∫°n tr·∫£ l·ªùi th·∫ø n√†o?

---

## SLIDE 3: B∆Ø·ªöC 1.1 - X√ÅC ƒê·ªäNH LO·∫†I B√ÄI TO√ÅN

**C√¢u h·ªèi ph√¢n t√≠ch:**

**Q1: ƒê√¢y l√† b√†i to√°n g√¨?**
- Classification? (ph√¢n lo·∫°i)
- Regression? (d·ª± ƒëo√°n s·ªë)
- Clustering? (ph√¢n nh√≥m)
- Anomaly Detection? (ph√°t hi·ªán b·∫•t th∆∞·ªùng)

**Q2: C√≥ labels kh√¥ng?**
- Supervised learning (c√≥ labels)
- Unsupervised learning (kh√¥ng labels)
- Semi-supervised (m·ªôt ph·∫ßn c√≥ labels)

---

## SLIDE 4: PH√ÇN T√çCH B√ÄI TO√ÅN - NETWORK ANOMALY

**ƒê·∫∑c ƒëi·ªÉm b√†i to√°n:**

‚úÖ **Ph√°t hi·ªán b·∫•t th∆∞·ªùng** (Anomaly Detection)
- M·ª•c ti√™u: T√¨m network events "l·∫°"
- Normal traffic: 99%
- Abnormal traffic: 1%

‚úÖ **Binary Classification** (n·∫øu c√≥ labels)
- Class 0: Normal traffic
- Class 1: Anomaly/Attack

‚úÖ **Highly Imbalanced**
- Anomaly r·∫•t hi·∫øm (1-5%)
- Kh√¥ng th·ªÉ d√πng accuracy ƒë∆°n thu·∫ßn

---

## SLIDE 5: QUY·∫æT ƒê·ªäNH LO·∫†I B√ÄI TO√ÅN

**3 Approaches c√≥ th·ªÉ d√πng:**

**Approach 1: Supervised Classification**
- C·∫ßn: Labeled data (normal + attack)
- Pros: Accuracy cao, bi·∫øt attack types
- Cons: C·∫ßn nhi·ªÅu labeled attack samples
- D√πng khi: C√≥ ƒë·ªß labeled historical data

**Approach 2: Unsupervised Anomaly Detection**
- C·∫ßn: Ch·ªâ c·∫ßn normal traffic data
- Pros: Ph√°t hi·ªán ƒë∆∞·ª£c unknown attacks
- Cons: False positive cao h∆°n
- D√πng khi: √çt labeled data, nhi·ªÅu zero-day

**Approach 3: Semi-supervised**
- C·∫ßn: Nhi·ªÅu normal + √≠t attack samples
- Pros: C√¢n b·∫±ng accuracy v√† flexibility
- Cons: Ph·ª©c t·∫°p h∆°n
- D√πng khi: Dataset th·ª±c t·∫ø (typical case)

---

## SLIDE 6: L·ª∞A CH·ªåN CHO B√ÄI TO√ÅN C·ª¶A CH√öNG TA

**Quy·∫øt ƒë·ªãnh: Supervised Binary Classification**

**L√Ω do:**
‚úÖ C√≥ historical attack logs (labeled)
‚úÖ Bi·∫øt r√µ attack types c·∫ßn detect
‚úÖ Business c·∫ßn gi·∫£i th√≠ch ƒë∆∞·ª£c decisions
‚úÖ C√≥ th·ªÉ train offline tr∆∞·ªõc khi deploy

**Lo·∫°i b√†i to√°n ch√≠nh th·ª©c:**
```
Binary Classification Problem
- Input: Network traffic features
- Output: {0: Normal, 1: Anomaly/Attack}
- Type: Supervised learning
- Challenge: Highly imbalanced data (99:1)
```

---

## SLIDE 7: B∆Ø·ªöC 1.2 - X√ÅC ƒê·ªäNH SUCCESS METRICS

**C√¢u h·ªèi quan tr·ªçng:**
"Model t·ªët" ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a th·∫ø n√†o?

**Metrics c√≥ th·ªÉ d√πng:**
- Accuracy?
- Precision?
- Recall?
- F1-Score?
- AUC-ROC?

**C√¢u h·ªèi:** Metric n√†o quan tr·ªçng nh·∫•t?

---

## SLIDE 8: PH√ÇN T√çCH COST C·ª¶A L·ªñI

**False Positive (FP): Model b√°o attack nh∆∞ng th·ª±c ra normal**

**Cost:**
- Block legitimate traffic
- Business disruption
- IT team ph·∫£i investigate (waste time)
- User complaints

**∆Ø·ªõc t√≠nh:** $500 per false alarm √ó 100 FP/day = $50,000/day ‚ùå

---

## SLIDE 9: PH√ÇN T√çCH COST C·ª¶A L·ªñI (tt)

**False Negative (FN): Model n√≥i normal nh∆∞ng th·ª±c ra l√† attack**

**Cost:**
- Attack kh√¥ng ƒë∆∞·ª£c ph√°t hi·ªán
- Data breach
- Financial loss
- Reputation damage
- Regulatory fines

**∆Ø·ªõc t√≠nh:** $1,000,000 per breach (average) üí•

**K·∫øt lu·∫≠n:** FN nguy hi·ªÉm h∆°n FP (1000x)

---

## SLIDE 10: CH·ªåN PRIMARY METRIC

**D·ª±a tr√™n cost analysis:**

**Primary Metric: RECALL (Sensitivity)**
```
Recall = TP / (TP + FN)
       = "Trong c√°c attack th·∫≠t, b·∫Øt ƒë∆∞·ª£c bao nhi√™u?"
```

**Y√™u c·∫ßu:** Recall ‚â• 95%
- B·ªè s√≥t t·ªëi ƒëa 5% attacks
- Ch·∫•p nh·∫≠n False Positive cao h∆°n

**Secondary Metrics:**
- Precision ‚â• 70% (gi·∫£m FP)
- F1-Score (c√¢n b·∫±ng)
- AUC-ROC ‚â• 0.90

---

## SLIDE 11: ƒê·ªäNH NGHƒ®A SUCCESS CRITERIA

**Model ƒë∆∞·ª£c coi l√† "th√†nh c√¥ng" khi:**

‚úÖ **Performance:**
- Recall ‚â• 95% (must-have)
- Precision ‚â• 70% (nice-to-have)
- F1-Score ‚â• 0.80
- AUC-ROC ‚â• 0.90

‚úÖ **Speed:**
- Inference time < 100ms per event
- Can process 10,000 events/second

‚úÖ **Size:**
- Model size < 100MB
- Deployable on edge devices

---

## SLIDE 12: B∆Ø·ªöC 1.3 - Y√äU C·∫¶U K·ª∏ THU·∫¨T

**Thu th·∫≠p y√™u c·∫ßu t·ª´ stakeholders:**

**From CTO:**
- Deploy trong 2 th√°ng
- Budget: $50K
- Must integrate v·ªõi existing SIEM

**From SOC Team:**
- Real-time alerts
- Explain why it's anomaly
- Dashboard v·ªõi visualizations
- False positive < 100/day

**From IT Ops:**
- High availability (99.9% uptime)
- Scalable (10K events/sec ‚Üí 100K)
- Easy to update/retrain

---

## SLIDE 13: Y√äU C·∫¶U CH·ª®C NƒÇNG

**Functional Requirements:**

**FR1: Detection**
- [ ] Detect DDoS attacks
- [ ] Detect port scanning
- [ ] Detect botnet traffic
- [ ] Detect data exfiltration
- [ ] Detect insider threats

**FR2: Alert System**
- [ ] Real-time alerts (<1 second)
- [ ] Severity levels (Low/Medium/High/Critical)
- [ ] Integration v·ªõi Slack/Email/SMS
- [ ] Incident ticket creation

**FR3: Dashboard**
- [ ] Traffic overview
- [ ] Attack statistics
- [ ] Model performance metrics
- [ ] Feature importance

---

## SLIDE 14: Y√äU C·∫¶U PHI CH·ª®C NƒÇNG

**Non-Functional Requirements:**

**NFR1: Performance**
```
Throughput:    ‚â• 10,000 events/second
Latency:       < 100ms (p95)
Model size:    < 100MB
Memory usage:  < 4GB RAM
```

**NFR2: Reliability**
```
Uptime:        99.9% (8.76 hours downtime/year)
MTBF:          > 720 hours
MTTR:          < 1 hour
Backup:        Daily automated
```

**NFR3: Scalability**
```
Horizontal:    Support 10+ nodes
Vertical:      Up to 32 cores, 128GB RAM
Auto-scaling:  Yes, based on load
```

---

## SLIDE 15: Y√äU C·∫¶U PHI CH·ª®C NƒÇNG (tt)

**NFR4: Security**
```
Authentication:  RBAC with AD integration
Encryption:      TLS 1.3 in-transit, AES-256 at-rest
Audit logging:   All predictions logged
Compliance:      SOC 2, ISO 27001
```

**NFR5: Maintainability**
```
Monitoring:      Prometheus + Grafana
Logging:         ELK stack
CI/CD:           Jenkins pipeline
Documentation:   Comprehensive docs + runbooks
```

**NFR6: Usability**
```
Training time:   < 4 hours for SOC analysts
UI/UX:           Intuitive dashboard
Explainability:  LIME/SHAP for predictions
```

---

## SLIDE 16: B∆Ø·ªöC 1.4 - BUSINESS CONTEXT

**Hi·ªÉu r√µ business domain:**

**Industry:** Financial Services (Banking)
- Highly regulated (PCI-DSS, GDPR)
- 24/7 operations
- Zero-tolerance for breaches
- Customer trust critical

**Current State:**
- Manual SOC monitoring
- 3 analysts √ó 8-hour shifts
- React to alerts (not proactive)
- Miss ~30% of attacks

**Target State:**
- AI-assisted detection
- Proactive threat hunting
- Reduce analyst workload 80%
- Catch 95%+ of attacks

---

## SLIDE 17: STAKEHOLDER ANALYSIS

**Primary Stakeholders:**

**1. SOC Team (Users)**
- Need: Easy-to-use tools
- Pain: Alert fatigue (500+ alerts/day)
- Success: Reduce alerts to 50/day
- Involvement: Daily users, feedback

**2. CTO (Sponsor)**
- Need: ROI proof
- Pain: Recent breaches ($2M loss)
- Success: No breaches in 6 months
- Involvement: Budget approval, reviews

**3. Compliance Officer**
- Need: Audit trail
- Pain: Regulatory fines risk
- Success: Pass audits
- Involvement: Compliance checks

---

## SLIDE 18: STAKEHOLDER ANALYSIS (tt)

**4. IT Operations (Support)**
- Need: Reliable system
- Pain: Downtime impacts business
- Success: 99.9% uptime
- Involvement: Deployment, maintenance

**5. Network Engineers (Data Source)**
- Need: Non-intrusive monitoring
- Pain: Tools slow down network
- Success: <1% performance impact
- Involvement: Data access, integration

**6. CISO (Decision Maker)**
- Need: Risk reduction
- Pain: Board pressure
- Success: Measurable security improvement
- Involvement: Final approval

---

## SLIDE 19: CONSTRAINTS & ASSUMPTIONS

**Constraints (Limitations):**

**Technical:**
- Must use existing network infrastructure
- Cannot install agents on endpoints
- Data retention: 90 days only
- Processing: On-premise only (no cloud)

**Resource:**
- Budget: $50K (including licenses)
- Team: 1 ML engineer, 1 DevOps
- Timeline: 2 months to MVP
- Compute: 2 servers (32 cores, 128GB each)

**Regulatory:**
- PCI-DSS Level 1 compliance
- GDPR data protection
- No PII in logs
- Audit logs required

---

## SLIDE 20: CONSTRAINTS & ASSUMPTIONS (tt)

**Assumptions (Need validation):**

‚úì Network logs are complete and accurate
‚úì Attack labels in historical data are correct
‚úì Network topology stable (no major changes)
‚úì SOC team will provide feedback
‚úì IT will support integration
‚úì Data quality is sufficient

**Risk if assumptions wrong:**
- Incomplete logs ‚Üí Poor model
- Wrong labels ‚Üí Train on bad data
- Topology changes ‚Üí Model outdated
- No feedback ‚Üí Can't improve

---

## SLIDE 21: B∆Ø·ªöC 1.5 - DOCUMENT REQUIREMENTS

**T·∫°o Requirements Document:**

**1. Problem Statement (1 page)**
```
Background:
- Current state
- Pain points
- Business impact

Proposed Solution:
- ML-based anomaly detection
- Real-time alerts
- Dashboard

Expected Outcomes:
- 95% detection rate
- 80% workload reduction
- ROI within 6 months
```

---

## SLIDE 22: DOCUMENT REQUIREMENTS (tt)

**2. Technical Specifications (2-3 pages)**
```
Input:
- Data source: Network flow logs (NetFlow, sFlow)
- Format: CSV/JSON
- Volume: 1M events/hour
- Features: 50+ fields

Output:
- Prediction: {0: Normal, 1: Anomaly}
- Confidence score: 0-100%
- Explanation: Top 3 contributing factors
- Alert: JSON to SIEM

Model:
- Type: Binary classifier
- Algorithms: Compare 5 (LR, RF, XGBoost, NN, Isolation Forest)
- Training: Weekly retrain
- Validation: 95% recall minimum
```

---

## SLIDE 23: DOCUMENT REQUIREMENTS (tt)

**3. Success Metrics (1 page)**
```
Primary (Must-Have):
‚úì Recall ‚â• 95%
‚úì Inference < 100ms
‚úì Uptime ‚â• 99.9%

Secondary (Nice-to-Have):
‚úì Precision ‚â• 70%
‚úì F1-Score ‚â• 0.80
‚úì False alerts < 100/day

Business Metrics:
‚úì Breach reduction: 80%
‚úì SOC efficiency: 80% improvement
‚úì Cost savings: $500K/year
‚úì ROI: 6 months payback
```

---

## SLIDE 24: DOCUMENT REQUIREMENTS (tt)

**4. Risks & Mitigation (1 page)**

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Insufficient labeled data | High | Medium | Use semi-supervised learning |
| High false positive rate | High | High | Tune threshold, ensemble methods |
| Concept drift | Medium | High | Weekly retraining pipeline |
| Integration issues | Medium | Low | POC with IT before full deploy |
| Performance degradation | High | Low | Load testing, auto-scaling |

---

## SLIDE 25: REVIEW CHECKLIST

**Phase 1 Complete khi:**

‚úÖ **Problem Definition:**
- [ ] Lo·∫°i b√†i to√°n x√°c ƒë·ªãnh r√µ r√†ng
- [ ] Input v√† output ƒë∆∞·ª£c m√¥ t·∫£ c·ª• th·ªÉ
- [ ] Supervised vs unsupervised ƒë√£ quy·∫øt ƒë·ªãnh

‚úÖ **Success Metrics:**
- [ ] Primary metric ƒë√£ ch·ªçn (Recall)
- [ ] Secondary metrics ƒë√£ list
- [ ] Threshold requirements ƒë√£ set
- [ ] Business metrics ƒë√£ align

‚úÖ **Requirements:**
- [ ] Functional requirements documented
- [ ] Non-functional requirements documented
- [ ] Constraints identified
- [ ] Assumptions listed

---

## SLIDE 26: REVIEW CHECKLIST (tt)

‚úÖ **Stakeholders:**
- [ ] All stakeholders identified
- [ ] Needs and pains understood
- [ ] Success criteria agreed
- [ ] Sign-off obtained

‚úÖ **Documentation:**
- [ ] Requirements doc created
- [ ] Reviewed by stakeholders
- [ ] Approved by sponsor (CTO)
- [ ] Shared with team

‚úÖ **Next Steps:**
- [ ] Phase 2: Data collection plan ready
- [ ] Team briefed
- [ ] Timeline confirmed

---

## SLIDE 27: COMMON MISTAKES - TR√ÅNH SAI L·∫¶M

**‚ùå Mistake 1: B·ªè qua Phase 1**
```
"M√¨nh c√≥ data r·ªìi, train model lu√¥n ƒëi!"
‚Üí L√†m sai b√†i to√°n, t·ªën th·ªùi gian

ƒê√∫ng: D√†nh 10% th·ªùi gian hi·ªÉu b√†i to√°n
      Ti·∫øt ki·ªám 50% th·ªùi gian sau n√†y
```

**‚ùå Mistake 2: Ch·ªâ nh√¨n accuracy**
```
"Model ƒë·∫°t 99% accuracy r·ªìi!"
‚Üí Nh∆∞ng b·ªè s√≥t 50% attacks (v√¨ imbalanced)

ƒê√∫ng: Ch·ªçn metric ph√π h·ª£p (Recall cho security)
```

---

## SLIDE 28: COMMON MISTAKES (tt)

**‚ùå Mistake 3: Kh√¥ng h·ªèi stakeholders**
```
ML engineer t·ª± quy·∫øt ƒë·ªãnh requirements
‚Üí Deploy xong, users kh√¥ng d√πng

ƒê√∫ng: Interview users, hi·ªÉu pain points th·∫≠t
```

**‚ùå Mistake 4: Unrealistic expectations**
```
"AI s·∫Ω detect 100% attacks, 0% false positive"
‚Üí Impossible, stakeholders th·∫•t v·ªçng

ƒê√∫ng: Set realistic goals (95% recall, 70% precision)
      Over-deliver thay v√¨ under-deliver
```

---

## SLIDE 29: COMMON MISTAKES (tt)

**‚ùå Mistake 5: Thi·∫øu documentation**
```
Nh·ªõ trong ƒë·∫ßu, kh√¥ng vi·∫øt ra
‚Üí 2 th√°ng sau qu√™n, team m·ªõi kh√¥ng hi·ªÉu

ƒê√∫ng: Document everything
      Future you s·∫Ω c·∫£m ∆°n present you
```

**‚ùå Mistake 6: Ignore constraints**
```
Train model c·∫ßn 1TB RAM, 10 GPUs
‚Üí C√¥ng ty kh√¥ng c√≥, deploy th·∫•t b·∫°i

ƒê√∫ng: Hi·ªÉu constraints t·ª´ ƒë·∫ßu
      Design solution ph√π h·ª£p
```

---

## SLIDE 30: OUTPUT C·ª¶A PHASE 1

**Deliverables:**

üìÑ **1. Requirements Document (5-10 pages)**
- Problem statement
- Technical specifications
- Success metrics
- Risks & mitigation

üìä **2. Project Charter (1 page)**
- Objective
- Scope
- Timeline
- Team
- Budget

üìã **3. Stakeholder Sign-off**
- CTO approval
- SOC manager approval
- IT ops approval

---

## SLIDE 31: OUTPUT C·ª¶A PHASE 1 (tt)

üìà **4. Success Metrics Dashboard (mockup)**
- Show how metrics will be tracked
- Set baseline (current state)
- Define targets

üóìÔ∏è **5. Project Plan**
```
Phase 1: Requirements     [DONE] ‚úÖ
Phase 2: Data Collection  [Week 1-2]
Phase 3: EDA              [Week 3]
Phase 4: Feature Eng      [Week 4]
Phase 5: Modeling         [Week 5-6]
Phase 6: Evaluation       [Week 7]
Phase 7: Deployment       [Week 8]
Phase 8: Monitoring       [Ongoing]
```

---

## SLIDE 32: T√ìM T·∫ÆT PHASE 1

**5 B∆∞·ªõc ƒë√£ th·ª±c hi·ªán:**

‚úÖ **B∆∞·ªõc 1.1:** X√°c ƒë·ªãnh lo·∫°i b√†i to√°n
- Binary classification
- Supervised learning
- Highly imbalanced

‚úÖ **B∆∞·ªõc 1.2:** X√°c ƒë·ªãnh success metrics
- Primary: Recall ‚â• 95%
- Secondary: Precision ‚â• 70%
- Business: Cost savings $500K/year

‚úÖ **B∆∞·ªõc 1.3:** Thu th·∫≠p requirements
- Functional: Detection types
- Non-functional: Performance, reliability

---

## SLIDE 33: T√ìM T·∫ÆT PHASE 1 (tt)

‚úÖ **B∆∞·ªõc 1.4:** Ph√¢n t√≠ch business context
- Stakeholders identified
- Pain points understood
- Constraints documented

‚úÖ **B∆∞·ªõc 1.5:** Document requirements
- Requirements doc created
- Sign-off obtained
- Team aligned

**Th·ªùi gian:** 2-4 gi·ªù well spent!

**K·∫øt qu·∫£:** Clear direction, aligned expectations, reduced risks

---

## SLIDE 34: TEMPLATE - PROBLEM DEFINITION

**Use this template for any ML project:**

```
1. WHAT?
   - What is the problem?
   - What is the goal?
   - What is success?

2. WHY?
   - Why is this important?
   - Why now?
   - Why ML (not rule-based)?

3. WHO?
   - Who are the users?
   - Who are the stakeholders?
   - Who will maintain it?

4. WHEN?
   - When is the deadline?
   - When will it be deployed?
   - When to retrain?

5. WHERE?
   - Where will it run? (cloud/on-premise)
   - Where is the data?
   - Where are the constraints?

6. HOW?
   - How will success be measured?
   - How will it integrate?
   - How will it be monitored?
```

---

## SLIDE 35: REAL-WORLD EXAMPLE 1

**Case: E-commerce Fraud Detection**

**Problem:**
- Fraud transactions: 0.1%
- Loss: $10M/year
- Manual review: Too slow

**Analysis:**
- Type: Binary classification (fraud/legitimate)
- Primary metric: Recall (catch fraudsters)
- Secondary: Precision (reduce false declines)
- Constraint: Real-time (<200ms)
- Success: 90% fraud caught, <5% false declines

---

## SLIDE 36: REAL-WORLD EXAMPLE 2

**Case: Medical Diagnosis (Cancer Detection)**

**Problem:**
- Radiologist shortage
- Need faster screening
- High stakes (life/death)

**Analysis:**
- Type: Binary classification (cancer/no cancer)
- Primary metric: Recall 99%+ (cannot miss cancer)
- Secondary: Precision 80%+ (reduce unnecessary biopsies)
- Constraint: Explainable (doctors need trust)
- Success: FDA approval, hospital adoption

---

## SLIDE 37: REAL-WORLD EXAMPLE 3

**Case: Predictive Maintenance (Factory)**

**Problem:**
- Unexpected equipment failures
- Downtime: $100K/hour
- Reactive maintenance expensive

**Analysis:**
- Type: Binary classification (will fail/won't fail)
- OR: Regression (remaining useful life prediction)
- Primary metric: Recall 95% (catch failures early)
- Constraint: Edge deployment (no cloud access)
- Success: 50% downtime reduction

---

## SLIDE 38: EXERCISE 1 - PH√ÇN T√çCH B√ÄI TO√ÅN

**Scenario:** Spam Email Detection

**Y√™u c·∫ßu:** X√°c ƒë·ªãnh c√°c th√¥ng tin sau:
1. Lo·∫°i b√†i to√°n?
2. Primary metric?
3. False Positive vs False Negative: C√°i n√†o nguy hi·ªÉm h∆°n?
4. Requirements ch√≠nh?

**Th·ªùi gian:** 10 ph√∫t th·∫£o lu·∫≠n nh√≥m

---

## SLIDE 39: EXERCISE 2 - CH·ªåN METRICS

**Cho c√°c b√†i to√°n sau, ch·ªçn primary metric:**

**1. Credit Card Approval**
- Approve good customers
- Reject risky customers
- Primary metric: ?

**2. Disease Outbreak Detection**
- Detect outbreak early
- Avoid panic (false alarms)
- Primary metric: ?

**3. Product Recommendation**
- User clicks on recommendations
- Maximize revenue
- Primary metric: ?

---

## SLIDE 40: ƒê√ÅP √ÅN EXERCISES

**Exercise 1: Spam Detection**
1. Binary classification (spam/not spam)
2. Primary: Precision (kh√¥ng x√≥a nh·∫ßm email quan tr·ªçng)
3. FP nguy hi·ªÉm h∆°n (m·∫•t email business critical)
4. Real-time, low FP, explainable

**Exercise 2: Metrics**
1. Credit Card: F1-Score (balance risk & opportunity)
2. Disease Outbreak: Recall (cannot miss outbreaks)
3. Product Recommendation: Precision@K, CTR

---

## SLIDE 41: BEST PRACTICES SUMMARY

**‚úÖ DO:**
- Spend 10% th·ªùi gian ·ªü Phase 1
- Interview real users
- Document everything
- Set realistic expectations
- Align with business goals
- Get stakeholder sign-off

**‚ùå DON'T:**
- Skip to coding immediately
- Assume you know the problem
- Choose metrics arbitrarily
- Ignore constraints
- Work in isolation
- Promise unrealistic results

---

## SLIDE 42: PHASE 1 CHECKLIST

**Print v√† check off:**

```
‚ñ° Lo·∫°i b√†i to√°n x√°c ƒë·ªãnh
‚ñ° Input/Output m√¥ t·∫£ r√µ
‚ñ° Primary metric ch·ªçn
‚ñ° Secondary metrics list
‚ñ° Threshold requirements set
‚ñ° Stakeholders interviewed
‚ñ° Requirements documented
‚ñ° Constraints identified
‚ñ° Assumptions listed
‚ñ° Risks assessed
‚ñ° Timeline agreed
‚ñ° Budget confirmed
‚ñ° Sign-off obtained
‚ñ° Team briefed
‚ñ° Ready for Phase 2
```

---

## SLIDE 43: CHUY·ªÇN SANG PHASE 2

**Phase 1 ho√†n th√†nh ‚Üí Phase 2: Data Collection**

**C√≥ trong tay:**
- Requirements document
- Success metrics defined
- Stakeholder buy-in
- Clear direction

**Phase 2 s·∫Ω l√†m g√¨:**
- Thu th·∫≠p network logs
- Exploratory Data Analysis
- Data quality assessment
- Feature identification

**Chu·∫©n b·ªã:**
- Access to network logs
- Analysis tools ready
- Team availability

---

## SLIDE 44: Q&A - COMMON QUESTIONS

**Q: Phase 1 c√≥ th·ªÉ skip n·∫øu b√†i to√°n r√µ r√†ng?**
A: KH√îNG! Lu√¥n l√†m Phase 1. "R√µ r√†ng" th∆∞·ªùng l√†Ï∞©illusion.

**Q: M·∫•t bao l√¢u cho Phase 1?**
A: 2-4 gi·ªù cho small project, 1-2 ng√†y cho large project.

**Q: N·∫øu stakeholder kh√¥ng available?**
A: Document assumptions, flag risks, proceed v·ªõi caution.

**Q: Metrics c√≥ th·ªÉ thay ƒë·ªïi sau?**
A: C√≥, nh∆∞ng c·∫ßn justify v√† get approval.

---

## SLIDE 45: T√ÄI LI·ªÜU THAM KH·∫¢O

**Books:**
- "Machine Learning Yearning" - Andrew Ng
- "Building Machine Learning Powered Applications" - Emmanuel Ameisen

**Templates:**
- ML Canvas: https://www.louisdorard.com/ml-canvas
- Project Charter template

**Tools:**
- JIRA/Trello: Project tracking
- Confluence: Documentation
- Google Docs: Collaborative editing

---

## SLIDE 46: HOMEWORK

**B√†i t·∫≠p v·ªÅ nh√†:**

**1. Ph√¢n t√≠ch b√†i to√°n m·ªõi (B·∫Øt bu·ªôc)**
- Ch·ªçn 1 b√†i to√°n ML b·∫•t k·ª≥
- Apply Phase 1 framework
- Vi·∫øt requirements document (2-3 pages)
- N·ªôp tu·∫ßn sau

**2. Critique existing project (N√¢ng cao)**
- T√¨m 1 ML project th·∫•t b·∫°i (news, blog)
- Ph√¢n t√≠ch: C√≥ th·ªÉ h·ªç b·ªè qua Phase 1 kh√¥ng?
- Present findings (5 ph√∫t)

---

## SLIDE 47: KEY TAKEAWAYS

**3 ƒëi·ªÅu quan tr·ªçng nh·∫•t:**

1. **Hi·ªÉu b√†i to√°n > Thu·∫≠t to√°n fancy**
   - 10% th·ªùi gian Phase 1
   - 50% th·ªùi gian ti·∫øt ki·ªám sau

2. **Metrics ph·∫£i align v·ªõi business**
   - Accuracy kh√¥ng ph·∫£i l√∫c n√†o c≈©ng ƒë√∫ng
   - Ch·ªçn metrics theo cost analysis

3. **Documentation is your friend**
   - Requirements doc = roadmap
   - Prevent scope creep
   - Enable communication

---

## SLIDE 48: REMEMBER

> "Hours spent in reconnaissance are seldom wasted."
> - Military proverb

> "Give me six hours to chop down a tree,  
> I will spend the first four sharpening the axe."
> - Abraham Lincoln

**Applied to ML:**
> "Give me two months to build ML system,  
> I will spend first week understanding the problem."

**Phase 1 = Sharpening your axe! ü™ì**

---

## SLIDE 49: NEXT CLASS PREVIEW

**Phase 2: Data Collection & EDA**

**Topics:**
- Network log formats (NetFlow, sFlow)
- Data collection strategies
- EDA techniques for network data
- Data quality assessment
- Feature identification

**Chu·∫©n b·ªã:**
- Review network protocols
- Install Wireshark (optional)
- Read v·ªÅ NetFlow format

---

## SLIDE 50: THANK YOU!

**Phase 1 Complete! üéâ**

**Questions?**

**Contact:**
- Email: [your-email]
- Office hours: [schedule]
- Slack: #module6-questions

**T√†i li·ªáu:**
- Slides: [link]
- Requirements template: [link]
- Example projects: [link]

**See you in Phase 2! üöÄ**

---





