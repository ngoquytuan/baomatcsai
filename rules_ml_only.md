# ğŸ¯ CHECKLIST & RULES CHO Má»ŒI Dá»° ÃN MACHINE LEARNING

**BEST PRACTICES** chung cho háº§u háº¿t dá»± Ã¡n ML, khÃ´ng riÃªng gÃ¬ bÃ i toÃ¡n security nÃ y.

---

## ğŸ“‹ ML PROJECT CHECKLIST - PHIÃŠN Báº¢N Äáº¦Y Äá»¦

---

## âœ… PHASE 1: HIá»‚U BÃ€I TOÃN (PROBLEM UNDERSTANDING)

### **1.1 XÃ¡c Ä‘á»‹nh loáº¡i bÃ i toÃ¡n**
- [ ] Classification (phÃ¢n loáº¡i)
  - [ ] Binary (2 classes): spam/not spam, fraud/normal
  - [ ] Multiclass (>2 classes): cat/dog/bird
  - [ ] Multilabel (nhiá»u labels cÃ¹ng lÃºc)
- [ ] Regression (dá»± Ä‘oÃ¡n sá»‘): giÃ¡ nhÃ , nhiá»‡t Ä‘á»™
- [ ] Clustering (phÃ¢n nhÃ³m): phÃ¢n khÃ¡ch hÃ ng
- [ ] Anomaly Detection (phÃ¡t hiá»‡n báº¥t thÆ°á»ng)
- [ ] Time Series (dá»¯ liá»‡u theo thá»i gian)

### **1.2 XÃ¡c Ä‘á»‹nh success metrics**
- [ ] Chá»n metric phÃ¹ há»£p vá»›i business:
  - Classification: Accuracy, Precision, Recall, F1, AUC-ROC
  - Regression: MAE, MSE, RMSE, RÂ²
  - Ranking: MAP, NDCG
- [ ] XÃ¡c Ä‘á»‹nh threshold cháº¥p nháº­n Ä‘Æ°á»£c (VD: accuracy >90%)
- [ ] XÃ¡c Ä‘á»‹nh yÃªu cáº§u vá» inference time (<100ms?)
- [ ] XÃ¡c Ä‘á»‹nh cost cá»§a False Positive vs False Negative

### **1.3 Thu tháº­p yÃªu cáº§u**
- [ ] Äá»™ chÃ­nh xÃ¡c cáº§n thiáº¿t
- [ ] Tá»‘c Ä‘á»™ inference
- [ ] KÃ­ch thÆ°á»›c model tá»‘i Ä‘a
- [ ] Kháº£ nÄƒng giáº£i thÃ­ch (interpretability)
- [ ] Äiá»u kiá»‡n deploy (cloud, edge, mobile)

---

## âœ… PHASE 2: THU THáº¬P & PHÃ‚N TÃCH Dá»® LIá»†U (DATA COLLECTION)

### **2.1 Thu tháº­p data**
- [ ] XÃ¡c Ä‘á»‹nh nguá»“n data: Production logs, APIs, Databases, Public datasets
- [ ] Äáº£m báº£o data Ä‘á»§ lá»›n (rule of thumb: 10-50 samples/feature tá»‘i thiá»ƒu)
- [ ] Kiá»ƒm tra quyá»n sá»­ dá»¥ng data (privacy, GDPR, licenses)
- [ ] Document data source vÃ  collection method

### **2.2 Exploratory Data Analysis (EDA)**
- [ ] Load data vÃ  check shape: `df.shape`
- [ ] Check data types: `df.dtypes`
- [ ] Check missing values: `df.isnull().sum()`
- [ ] Check duplicates: `df.duplicated().sum()`
- [ ] Statistical summary: `df.describe()`
- [ ] Visualize distributions: histograms, box plots
- [ ] Check correlations: `df.corr()`
- [ ] Identify outliers

### **2.3 Label Distribution (cho classification)**
- [ ] Check imbalanced data: `df['label'].value_counts()`
- [ ] Náº¿u imbalanced (<30% minority class):
  - [ ] Consider SMOTE, oversampling, undersampling
  - [ ] Consider class weights
  - [ ] Consider anomaly detection approach
  - [ ] Use stratified split

---

## âœ… PHASE 3: FEATURE ENGINEERING

### **3.1 Feature Selection**
- [ ] Domain expertise: Chá»n features cÃ³ Ã½ nghÄ©a business
- [ ] Remove low-variance features
- [ ] Remove highly correlated features (>0.95)
- [ ] Feature importance analysis
- [ ] Curse of dimensionality: KhÃ´ng quÃ¡ nhiá»u features so vá»›i samples

### **3.2 Feature Creation**
- [ ] Táº¡o interaction features náº¿u cáº§n
- [ ] Binning/discretization cho continuous features
- [ ] Encoding categorical features:
  - [ ] One-hot encoding (cho nominal)
  - [ ] Label encoding (cho ordinal)
  - [ ] Target encoding (cáº©n tháº­n data leakage)
- [ ] Date/time features: hour, day_of_week, month, is_weekend
- [ ] Text features: TF-IDF, word embeddings

### **3.3 Feature Validation**
- [ ] Äáº£m báº£o features cÃ³ thá»ƒ thu tháº­p á»Ÿ production
- [ ] KhÃ´ng dÃ¹ng features cÃ³ data leakage
- [ ] KhÃ´ng dÃ¹ng features vi pháº¡m privacy

---

## âœ… PHASE 4: DATA SPLITTING (QUAN TRá»ŒNG!)

### **4.1 Train/Validation/Test Split**
**RULE 1: LuÃ´n chia data TRÆ¯á»šC KHI lÃ m báº¥t cá»© Ä‘iá»u gÃ¬ khÃ¡c!**

```python
# CÃ¡ch 1: Train/Test split (Ä‘Æ¡n giáº£n)
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,        # RULE 2: ThÆ°á»ng 0.2 hoáº·c 0.3
    random_state=42,      # RULE 3: LuÃ´n set Ä‘á»ƒ reproducible
    stratify=y            # RULE 4: Vá»›i classification, luÃ´n stratify
)

# CÃ¡ch 2: Train/Val/Test split (khuyáº¿n khÃ­ch)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
)
# Káº¿t quáº£: 60% train, 20% val, 20% test
```

### **4.2 Split Rules chi tiáº¿t**

**RULE 2: test_size phá»¥ thuá»™c dataset size**
```
Dataset Size         Recommended Split
< 1,000             70/30 hoáº·c 80/20
1,000 - 10,000      80/20
10,000 - 100,000    85/15 hoáº·c 90/10
> 100,000           90/10 hoáº·c 95/5
```

**RULE 3: random_state**
- [ ] LuÃ´n set random_state (VD: 42, 123, 2024)
- [ ] GiÃºp reproduce káº¿t quáº£
- [ ] DÃ¹ng cÃ¹ng má»™t giÃ¡ trá»‹ trong suá»‘t project
- [ ] Document giÃ¡ trá»‹ Ä‘Ã£ chá»n

**RULE 4: stratify cho classification**
- [ ] LuÃ´n dÃ¹ng `stratify=y` vá»›i classification
- [ ] Äáº£m báº£o tá»· lá»‡ class giá»‘ng nhau giá»¯a train/val/test
- [ ] Äáº·c biá»‡t quan trá»ng vá»›i imbalanced data

**RULE 5: Time-based split cho time series**
```python
# KHÃ”NG dÃ¹ng random split vá»›i time series!
# DÃ¹ng time-based split:
train = df[df['date'] < '2024-01-01']
test = df[df['date'] >= '2024-01-01']
```

### **4.3 Data Leakage Prevention (Cá»°C Ká»² QUAN TRá»ŒNG!)**

**RULE 6: KHÃ”NG BAO GIá»œ Ä‘á»ƒ test data "nhÃ¬n tháº¥y" trong training!**

```python
# âŒ SAI - Fit scaler trÃªn toÃ n bá»™ data
scaler.fit(X)  # Leak test data info!
X_train, X_test = train_test_split(X)

# âœ… ÄÃšNG - Fit chá»‰ trÃªn training data
X_train, X_test = train_test_split(X)
scaler.fit(X_train)  # Chá»‰ há»c tá»« train
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

**RULE 7: Kiá»ƒm tra overlap**
```python
train_set = set(map(tuple, X_train.values))
test_set = set(map(tuple, X_test.values))
overlap = train_set & test_set
assert len(overlap) == 0, "Data leakage detected!"
```

---

## âœ… PHASE 5: DATA PREPROCESSING

### **5.1 Handle Missing Values**
- [ ] Identify missing patterns: `df.isnull().sum()`
- [ ] Decide strategy:
  - [ ] Drop rows (náº¿u <5% missing)
  - [ ] Imputation: mean, median, mode
  - [ ] Advanced: KNN imputer, iterative imputer
  - [ ] Create "missing" indicator feature
- [ ] **RULE 8: Fit imputer chá»‰ trÃªn training data!**

### **5.2 Handle Outliers**
- [ ] Detect: IQR method, Z-score
- [ ] Decide: Keep, cap, remove, transform
- [ ] Document outlier handling strategy

### **5.3 Feature Scaling**
**RULE 9: Scaling rules theo algorithm**

| Algorithm | Scaling cáº§n? | Method |
|-----------|--------------|--------|
| Logistic Regression | âœ… Cáº¦N | StandardScaler |
| SVM | âœ… Cáº¦N | StandardScaler |
| Neural Networks | âœ… Cáº¦N | StandardScaler hoáº·c MinMaxScaler |
| KNN | âœ… Cáº¦N | StandardScaler |
| Naive Bayes | âŒ KHÃ”NG | - |
| Decision Tree | âŒ KHÃ”NG | - |
| Random Forest | âŒ KHÃ”NG | - |
| XGBoost | âŒ KHÃ”NG | - |

**RULE 10: Fit scaler chá»‰ trÃªn training!**
```python
# âœ… ÄÃšNG
scaler = StandardScaler()
scaler.fit(X_train)  # Chá»‰ há»c tá»« train
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

# âŒ SAI
scaler.fit(pd.concat([X_train, X_test]))  # Leak!
```

**StandardScaler vs MinMaxScaler:**
```
StandardScaler: (x - mean) / std
- Káº¿t quáº£: mean=0, std=1
- DÃ¹ng khi: Data cÃ³ outliers, distribution tÆ°Æ¡ng Ä‘á»‘i normal

MinMaxScaler: (x - min) / (max - min)
- Káº¿t quáº£: range [0, 1]
- DÃ¹ng khi: Cáº§n bounded range, neural networks vá»›i sigmoid/tanh
```

---

## âœ… PHASE 6: MODEL SELECTION & TRAINING

### **6.1 Baseline Model**
**RULE 11: LuÃ´n báº¯t Ä‘áº§u vá»›i baseline Ä‘Æ¡n giáº£n!**
- [ ] Classification: Dummy classifier (most frequent)
- [ ] Regression: Mean/median predictor
- [ ] Má»¥c Ä‘Ã­ch: CÃ³ baseline Ä‘á»ƒ so sÃ¡nh

### **6.2 Chá»n Algorithms**
**RULE 12: Chá»n algorithm phÃ¹ há»£p vá»›i bÃ i toÃ¡n**

**Cho Classification:**
```
Dataset nhá» (<10K):
â”œâ”€ Linear data â†’ Logistic Regression
â”œâ”€ Non-linear â†’ SVM with RBF kernel
â””â”€ Tree-based â†’ Random Forest, XGBoost

Dataset lá»›n (>10K):
â”œâ”€ Deep Learning náº¿u cÃ³: images, text, complex patterns
â”œâ”€ XGBoost/LightGBM cho tabular data
â””â”€ Ensemble methods
```

**Cho Regression:**
```
â”œâ”€ Linear Regression (baseline)
â”œâ”€ Ridge/Lasso (náº¿u cÃ³ nhiá»u features)
â”œâ”€ Random Forest Regressor
â”œâ”€ XGBoost/LightGBM
â””â”€ Neural Networks (dataset lá»›n)
```

### **6.3 Training Strategy**
**RULE 13: Train nhiá»u models vÃ  so sÃ¡nh**
- [ ] Ãt nháº¥t 3-5 algorithms khÃ¡c nhau
- [ ] So sÃ¡nh trÃªn validation set
- [ ] Track training time, model size, inference speed

**RULE 14: Cross-validation cho dataset nhá»**
```python
from sklearn.model_selection import cross_val_score

# K-fold CV (thÆ°á»ng k=5 hoáº·c 10)
scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
print(f"CV Accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})")
```

**Khi nÃ o dÃ¹ng CV:**
- Dataset nhá» (<5000 samples)
- Cáº§n Ä‘Ã¡nh giÃ¡ robust
- CÃ³ thá»i gian training

**Khi nÃ o KHÃ”NG dÃ¹ng CV:**
- Dataset lá»›n (>50K) â†’ Chá»‰ cáº§n train/val/test split
- Time series data â†’ DÃ¹ng TimeSeriesSplit
- Production vá»›i time constraints

---

## âœ… PHASE 7: MODEL EVALUATION

### **7.1 Evaluation Metrics**
**RULE 15: DÃ¹ng nhiá»u metrics, khÃ´ng chá»‰ accuracy!**

**Classification:**
```python
from sklearn.metrics import classification_report, confusion_matrix

# Must-have metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print(f"TN={cm[0,0]}, FP={cm[0,1]}")
print(f"FN={cm[1,0]}, TP={cm[1,1]}")

# Advanced
roc_auc = roc_auc_score(y_test, y_proba)
```

**RULE 16: Hiá»ƒu trade-offs cá»§a tá»«ng metric**
```
Accuracy: Tá»•ng quan, nhÆ°ng sai lá»‡ch vá»›i imbalanced data
Precision: "Trong cÃ¡c dá»± Ä‘oÃ¡n positive, cÃ³ bao nhiÃªu Ä‘Ãºng?"
          â†’ Quan trá»ng khi False Positive tá»‘n kÃ©m
Recall: "Trong cÃ¡c positive tháº­t, báº¯t Ä‘Æ°á»£c bao nhiÃªu?"
       â†’ Quan trá»ng khi False Negative nguy hiá»ƒm (security, medical)
F1: CÃ¢n báº±ng Precision vÃ  Recall
```

**RULE 17: Chá»n metric theo business context**
```
Spam detection: Precision cao (Ã­t xÃ³a nháº§m email quan trá»ng)
Cancer detection: Recall cao (khÃ´ng bá» sÃ³t bá»‡nh nhÃ¢n)
Fraud detection: F1 hoáº·c Recall cao (khÃ´ng bá» sÃ³t gian láº­n)
Recommendation: MAP, NDCG
```

### **7.2 Confusion Matrix Analysis**
**RULE 18: LuÃ´n phÃ¢n tÃ­ch confusion matrix chi tiáº¿t**
```
                 Predicted
              Negative  Positive
Actual Neg      TN        FP      â† Type I Error
       Pos      FN        TP      â† Type II Error

FP (False Positive): BÃ¡o Ä‘á»™ng giáº£ â†’ LÃ m phiá»n user
FN (False Negative): Bá» sÃ³t â†’ Nguy hiá»ƒm!
```

### **7.3 Learning Curves**
- [ ] Plot training vs validation curves
- [ ] Identify overfitting/underfitting
- [ ] Decide next steps

---

## âœ… PHASE 8: HYPERPARAMETER TUNING

### **8.1 Tuning Strategy**
**RULE 19: Tune trÃªn validation set, KHÃ”NG pháº£i test set!**

```python
# âŒ SAI - Tune trÃªn test set
best_params = tune_on_test_set()  # Test set leak!

# âœ… ÄÃšNG - Tune trÃªn validation set
best_params = tune_on_validation_set()
final_test = evaluate_on_test_set(best_params)
```

### **8.2 Tuning Methods**
**RULE 20: Báº¯t Ä‘áº§u vá»›i Grid Search, sau Ä‘Ã³ Random Search**

```python
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

# Grid Search (nhá», exhaustive)
param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['rbf', 'linear']
}
grid = GridSearchCV(SVM(), param_grid, cv=5)

# Random Search (lá»›n, faster)
param_dist = {
    'n_estimators': [50, 100, 200, 500],
    'max_depth': [5, 10, 20, None],
    'min_samples_split': [2, 5, 10]
}
random = RandomizedSearchCV(RF(), param_dist, n_iter=20, cv=5)
```

**Advanced: Bayesian Optimization**
- DÃ¹ng cho expensive models (deep learning)
- Libraries: Optuna, Hyperopt

### **8.3 Overfitting Prevention**
**RULE 21: Watch out for overfitting signs**
```
Signs:
- Train accuracy >> Test accuracy (>10% gap)
- Model quÃ¡ phá»©c táº¡p
- Training loss giáº£m nhÆ°ng val loss tÄƒng

Solutions:
- Regularization (L1, L2, dropout)
- Reduce model complexity
- Get more data
- Data augmentation
- Early stopping
```

---

## âœ… PHASE 9: MODEL COMPARISON

### **9.1 Comparison Criteria**
**RULE 22: So sÃ¡nh Ä‘a chiá»u, khÃ´ng chá»‰ accuracy**

| Model | Accuracy | Precision | Recall | F1 | Training Time | Inference Time | Model Size |
|-------|----------|-----------|--------|----|--------------:|---------------:|-----------:|
| LR | 0.85 | 0.83 | 0.87 | 0.85 | 0.1s | 0.001s | 1 KB |
| RF | 0.92 | 0.90 | 0.94 | 0.92 | 5s | 0.05s | 500 KB |
| NN | 0.93 | 0.91 | 0.95 | 0.93 | 300s | 0.02s | 10 MB |

### **9.2 Selection Criteria**
- [ ] Performance metrics (primary)
- [ ] Inference speed (production requirement)
- [ ] Model size (deployment constraint)
- [ ] Interpretability (business requirement)
- [ ] Training time (iteration speed)
- [ ] Maintenance cost

---

## âœ… PHASE 10: FINAL EVALUATION

### **10.1 Test Set Evaluation**
**RULE 23: Test set chá»‰ dÃ¹ng Má»˜T Láº¦N cuá»‘i cÃ¹ng!**
```python
# âŒ SAI - Test nhiá»u láº§n
for model in models:
    test_score = evaluate(model, X_test, y_test)
    if test_score > best:
        best_model = model  # Overfitting to test set!

# âœ… ÄÃšNG - Select trÃªn validation, test cuá»‘i
best_model = select_on_validation()
final_score = evaluate_once(best_model, X_test, y_test)
```

### **10.2 Final Checks**
- [ ] Evaluate trÃªn test set Má»˜T Láº¦N duy nháº¥t
- [ ] Document táº¥t cáº£ metrics
- [ ] Verify model meets requirements
- [ ] Test edge cases
- [ ] Analyze errors (FP, FN cases)

---

## âœ… PHASE 11: MODEL DEPLOYMENT

### **11.1 Model Saving**
**RULE 24: Save model vÃ  preprocessing objects**
```python
import pickle

# Save model
pickle.dump(model, open('model.pkl', 'wb'))

# Save scaler (QUAN TRá»ŒNG!)
pickle.dump(scaler, open('scaler.pkl', 'wb'))

# Save feature names
pickle.dump(feature_names, open('features.pkl', 'wb'))
```

### **11.2 Inference Pipeline**
```python
def predict_new_data(new_data):
    # 1. Load model vÃ  scaler
    model = pickle.load(open('model.pkl', 'rb'))
    scaler = pickle.load(open('scaler.pkl', 'rb'))
    
    # 2. Preprocessing (giá»‘ng training!)
    new_data_scaled = scaler.transform(new_data)
    
    # 3. Predict
    prediction = model.predict(new_data_scaled)
    probability = model.predict_proba(new_data_scaled)
    
    return prediction, probability
```

### **11.3 Production Checklist**
- [ ] API endpoint ready
- [ ] Input validation
- [ ] Error handling
- [ ] Logging
- [ ] Monitoring setup
- [ ] A/B testing plan
- [ ] Rollback plan

---

## âœ… PHASE 12: MONITORING & MAINTENANCE

### **12.1 Model Monitoring**
**RULE 25: LuÃ´n monitor model trong production**
- [ ] Track performance metrics daily/weekly
- [ ] Monitor data drift
- [ ] Monitor concept drift
- [ ] Set up alerts for anomalies

### **12.2 Retraining Strategy**
- [ ] Schedule periodic retraining
- [ ] Retrain when performance drops >5%
- [ ] Retrain when data distribution changes
- [ ] Version control for models

---

## ğŸ“‹ QUICK CHECKLIST - IN RA DÃN TÆ¯á»œNG

```
â–¡ Hiá»ƒu bÃ i toÃ¡n & chá»n metrics
â–¡ EDA: shape, dtypes, missing, distribution, correlation
â–¡ Split data: train/val/test (stratify náº¿u classification)
â–¡ Check data leakage: overlap = 0
â–¡ Handle missing values (fit trÃªn train only)
â–¡ Feature engineering & selection
â–¡ Scaling (fit trÃªn train only, theo algorithm)
â–¡ Train baseline model
â–¡ Train multiple models (3-5)
â–¡ Cross-validation (dataset nhá»)
â–¡ Evaluate vá»›i nhiá»u metrics
â–¡ PhÃ¢n tÃ­ch confusion matrix
â–¡ Hyperparameter tuning (trÃªn validation)
â–¡ So sÃ¡nh models Ä‘a chiá»u
â–¡ Final test evaluation (Má»˜T Láº¦N)
â–¡ Save model + scaler + features
â–¡ Deploy vá»›i monitoring
â–¡ Set up retraining pipeline
```

---

## ğŸš¨ TOP 10 Lá»–I THÆ¯á»œNG Gáº¶P

1. **Data Leakage** - Fit scaler/imputer trÃªn toÃ n bá»™ data
2. **KhÃ´ng stratify** - Class imbalance giá»¯a train/test
3. **QuÃªn set random_state** - Káº¿t quáº£ khÃ´ng reproducible
4. **Overfit to test set** - Test nhiá»u láº§n vÃ  chá»n best
5. **Chá»‰ nhÃ¬n accuracy** - Bá» qua precision, recall, F1
6. **KhÃ´ng check imbalanced data** - Accuracy giáº£ táº¡o cao
7. **Scaling sai** - Scale test data Ä‘á»™c láº­p train
8. **QuÃªn save scaler** - Production khÃ´ng scale Ä‘Ãºng
9. **KhÃ´ng validate edge cases** - Model fail á»Ÿ corner cases
10. **KhÃ´ng monitor production** - Performance degradation

