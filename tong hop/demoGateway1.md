# ===============================
# SMTP AI Gateway Demo â€“ Python Skeleton
# FastAPI + WebSocket + SQLite/In-Memory Inbox + Naive Bayes (stub) + LLM (stub)
# ===============================
# Project layout (single file for demo; split into modules in real project):
# - config: settings & feature flags
# - models: Pydantic schemas
# - storage: Inbox (SQLite or in-memory)
# - filters.naive_bayes: placeholder train/predict
# - filters.llm: provider-agnostic LLM call stubs (OpenAI/OpenRouter/Grok)
# - filters.policy: decision orchestration (NB -> LLM on suspicion)
# - gateway: FastAPI app with HTTP + WebSocket endpoints
# - run: Uvicorn entrypoint
# ===============================

from __future__ import annotations

import asyncio
import json
import logging
import os
import queue
import sqlite3
import time
from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, List, Optional

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi import Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

# -------------------------------
# config
# -------------------------------
class Settings(BaseModel):
    app_name: str = "smtp-ai-gateway-demo"
    use_sqlite: bool = False  # switch to True to persist inbox
    sqlite_path: str = "/tmp/inbox.db"
    enable_ws: bool = True

    # Naive Bayes thresholds (stub)
    nb_suspicious_threshold: float = 0.6  # >= triggers LLM

    # LLM providers (only one needs to be configured; all are optional in skeleton)
    llm_provider: str = "openai"  # openai | openrouter | grok
    openai_api_key: Optional[str] = None
    openrouter_api_key: Optional[str] = None
    grok_api_key: Optional[str] = None

    # Safety / demo flags
    allow_external_llm_calls: bool = False  # keep False in skeleton


SETTINGS = Settings()

# -------------------------------
# models (schemas)
# -------------------------------
class Message(BaseModel):
    sender: str = Field(..., description="email-like identifier of sender")
    receiver: str = Field(..., description="email-like identifier of receiver")
    subject: str = Field("", description="message subject")
    body: str = Field(..., description="message body text (no HTML in demo)")
    thread_id: Optional[str] = Field(None, description="conversation/thread id")
    timestamp: float = Field(default_factory=lambda: time.time())


class ClassifiedMessage(Message):
    nb_score: float = 0.0
    llm_verdict: Optional[str] = None  # "ok" | "scam" | None
    decision: str = "delivered"  # delivered | flagged | blocked
    reason: Optional[str] = None


class TrainItem(BaseModel):
    text: str
    label: str  # "legit" | "phishing" | "bec"


class TrainSet(BaseModel):
    items: List[TrainItem]


# -------------------------------
# utils: simple preprocessing (stub)
# -------------------------------
class TextPreprocessor:
    @staticmethod
    def normalize(text: str) -> str:
        # TODO: lowercase, strip diacritics, remove HTML, collapse whitespace, etc.
        return " ".join(text.lower().split())


# -------------------------------
# storage: Inbox implementations
# -------------------------------
class InboxBase:
    def save(self, msg: ClassifiedMessage) -> None:
        raise NotImplementedError

    def list(self, limit: int = 100) -> List[ClassifiedMessage]:
        raise NotImplementedError


class InMemoryInbox(InboxBase):
    def __init__(self) -> None:
        self._msgs: List[ClassifiedMessage] = []

    def save(self, msg: ClassifiedMessage) -> None:
        self._msgs.append(msg)

    def list(self, limit: int = 100) -> List[ClassifiedMessage]:
        return list(reversed(self._msgs))[:limit]


class SQLiteInbox(InboxBase):
    def __init__(self, path: str) -> None:
        self._conn = sqlite3.connect(path, check_same_thread=False)
        self._init_schema()

    def _init_schema(self) -> None:
        cur = self._conn.cursor()
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS inbox(
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                json TEXT NOT NULL,
                ts REAL NOT NULL
            )
            """
        )
        self._conn.commit()

    def save(self, msg: ClassifiedMessage) -> None:
        cur = self._conn.cursor()
        cur.execute(
            "INSERT INTO inbox(json, ts) VALUES(?, ?)",
            (msg.json(), msg.timestamp),
        )
        self._conn.commit()

    def list(self, limit: int = 100) -> List[ClassifiedMessage]:
        cur = self._conn.cursor()
        cur.execute("SELECT json FROM inbox ORDER BY id DESC LIMIT ?", (limit,))
        rows = cur.fetchall()
        out: List[ClassifiedMessage] = []
        for (j,) in rows:
            out.append(ClassifiedMessage.parse_raw(j))
        return out


# Dependency factory
INBOX: InboxBase = SQLiteInbox(SETTINGS.sqlite_path) if SETTINGS.use_sqlite else InMemoryInbox()


# -------------------------------
# filters: Naive Bayes (stub)
# -------------------------------
class NaiveBayesFilter:
    """Skeleton NB classifier. In real code, store vocabulary, priors, likelihoods.
    Here we return a heuristic score for demo purposes.
    """

    def __init__(self) -> None:
        self.trained = False
        self.keywords_suspicious = {
            "chuyá»ƒn khoáº£n", "tÃ i khoáº£n má»›i", "kháº©n", "gáº¥p", "invoice", "bank", "swift",
            "update account", "wire", "urgent", "gift card", "otp", "reset password",
        }

    def train(self, dataset: TrainSet) -> None:
        # TODO: build vocabulary, compute P(class), P(token|class)
        self.trained = True

    def predict_proba(self, text: str) -> float:
        """Return probability that text is suspicious (0..1). Pure heuristic for skeleton."""
        if not self.trained:
            # Conservative default if not trained
            return 0.5
        norm = TextPreprocessor.normalize(text)
        tokens = set(norm.split())
        hit = len(tokens & self.keywords_suspicious)
        # Map keyword hits to a crude probability
        return min(1.0, 0.2 + 0.15 * hit)


NB_FILTER = NaiveBayesFilter()


# -------------------------------
# filters: LLM Analyzer (provider-agnostic stubs)
# -------------------------------
class LLMVerdict(str, Enum):
    ok = "ok"
    scam = "scam"
    uncertain = "uncertain"


class LLMAnalyzer:
    def __init__(self, settings: Settings) -> None:
        self.settings = settings

    async def analyze(self, msg: Message, nb_score: float) -> LLMVerdict:
        """Skeleton: call out to provider or return deterministic local verdict.
        Do NOT send data to external API unless allow_external_llm_calls=True.
        """
        prompt = self._build_prompt(msg, nb_score)
        if not self.settings.allow_external_llm_calls:
            # Local heuristic fallback for demo
            if nb_score >= 0.85:
                return LLMVerdict.scam
            if nb_score >= 0.6:
                return LLMVerdict.uncertain
            return LLMVerdict.ok
        # Otherwise, pick provider
        provider = (self.settings.llm_provider or "openai").lower()
        if provider == "openrouter":
            return await self._call_openrouter(prompt)
        if provider == "grok":
            return await self._call_grok(prompt)
        return await self._call_openai(prompt)

    def _build_prompt(self, msg: Message, nb_score: float) -> str:
        return (
            "You are an email security analyst. Classify the following message as 'ok' or 'scam'\n"
            f"NB_suspicion_score: {nb_score}\n"
            f"From: {msg.sender}\nTo: {msg.receiver}\nSubject: {msg.subject}\nBody: {msg.body}\n"
            "Explain briefly and output a single token label: ok or scam."
        )

    async def _call_openai(self, prompt: str) -> LLMVerdict:
        # TODO: implement with openai SDK
        # Placeholder behavior
        await asyncio.sleep(0.05)
        return LLMVerdict.uncertain

    async def _call_openrouter(self, prompt: str) -> LLMVerdict:
        # TODO: implement with OpenRouter HTTP API
        await asyncio.sleep(0.05)
        return LLMVerdict.uncertain

    async def _call_grok(self, prompt: str) -> LLMVerdict:
        # TODO: implement with xAI Grok API
        await asyncio.sleep(0.05)
        return LLMVerdict.uncertain


LLM = LLMAnalyzer(SETTINGS)


# -------------------------------
# filters: Policy / Orchestration
# -------------------------------
class Decision(str, Enum):
    delivered = "delivered"
    flagged = "flagged"
    blocked = "blocked"


class PolicyEngine:
    def __init__(self, nb: NaiveBayesFilter, llm: LLMAnalyzer, settings: Settings) -> None:
        self.nb = nb
        self.llm = llm
        self.settings = settings

    async def evaluate(self, msg: Message) -> ClassifiedMessage:
        nb_score = self.nb.predict_proba(f"{msg.subject} \n {msg.body}")
        if nb_score < self.settings.nb_suspicious_threshold:
            return ClassifiedMessage(**msg.dict(), nb_score=nb_score, decision=Decision.delivered)

        # Suspicious â†’ escalate to LLM
        verdict = await self.llm.analyze(msg, nb_score)
        if verdict == LLMVerdict.scam:
            return ClassifiedMessage(
                **msg.dict(),
                nb_score=nb_score,
                llm_verdict=verdict,
                decision=Decision.blocked,
                reason="LLM: likely BEC/phishing",
            )
        if verdict == LLMVerdict.uncertain:
            return ClassifiedMessage(
                **msg.dict(),
                nb_score=nb_score,
                llm_verdict=verdict,
                decision=Decision.flagged,
                reason="Suspicious content â€“ manual review",
            )
        return ClassifiedMessage(**msg.dict(), nb_score=nb_score, llm_verdict=verdict, decision=Decision.delivered)


POLICY = PolicyEngine(NB_FILTER, LLM, SETTINGS)


# -------------------------------
# gateway: FastAPI app
# -------------------------------
app = FastAPI(title="SMTP AI Gateway â€“ Demo", version="0.1.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/health")
def health() -> Dict[str, Any]:
    return {"status": "ok", "app": SETTINGS.app_name}


@app.post("/train")
def train(data: TrainSet) -> Dict[str, Any]:
    NB_FILTER.train(data)
    return {"status": "trained", "items": len(data.items)}


@app.post("/send", response_model=ClassifiedMessage)
async def send(msg: Message) -> ClassifiedMessage:
    classified = await POLICY.evaluate(msg)
    if classified.decision != Decision.blocked:
        INBOX.save(classified)
    return classified


@app.get("/inbox", response_model=List[ClassifiedMessage])
def inbox(limit: int = 100) -> List[ClassifiedMessage]:
    return INBOX.list(limit=limit)


# --- Optional WebSocket for live streaming decisions ---
class ConnectionManager:
    def __init__(self) -> None:
        self.active: List[WebSocket] = []

    async def connect(self, ws: WebSocket) -> None:
        await ws.accept()
        self.active.append(ws)

    def disconnect(self, ws: WebSocket) -> None:
        if ws in self.active:
            self.active.remove(ws)

    async def broadcast(self, message: Dict[str, Any]) -> None:
        for ws in list(self.active):
            try:
                await ws.send_text(json.dumps(message))
            except Exception:
                self.disconnect(ws)


WS_MANAGER = ConnectionManager()


@app.websocket("/ws")
async def ws_endpoint(ws: WebSocket):
    if not SETTINGS.enable_ws:
        await ws.close(code=4403)
        return
    await WS_MANAGER.connect(ws)
    try:
        while True:
            data = await ws.receive_text()
            payload = json.loads(data)
            msg = Message(**payload)
            classified = await POLICY.evaluate(msg)
            if classified.decision != Decision.blocked:
                INBOX.save(classified)
            await WS_MANAGER.broadcast({"event": "classified", "data": classified.dict()})
    except WebSocketDisconnect:
        WS_MANAGER.disconnect(ws)


# -------------------------------
# run: uvicorn entrypoint (for local dev)
# -------------------------------
# Usage:
#   uvicorn this_file:app --reload --port 8080
#   curl -X POST http://localhost:8080/send -H 'Content-Type: application/json' \
#        -d '{"sender":"alice@corp.com","receiver":"ap@vendor.com","subject":"Thanh toÃ¡n","body":"Vui lÃ²ng chuyá»ƒn khoáº£n vÃ o tÃ i khoáº£n má»›i."}'
#   curl http://localhost:8080/inbox
# -------------------------------



  

ÄÃ£ dá»±ng xong skeleton code vÃ o canvas cho báº¡n rá»“i â€” gá»“m FastAPI gateway, inbox (SQLite/in-memory), bá»™ lá»c Naive Bayes â€œstubâ€, lá»›p gá»i LLM (OpenAI/OpenRouter/Grok) dáº¡ng adapter, policy Ä‘iá»u phá»‘i, HTTP + WebSocket endpoint, vÃ  hÆ°á»›ng cháº¡y báº±ng uvicorn.

Báº¡n muá»‘n mÃ¬nh:

* tÃ¡ch ra thÃ nh nhiá»u file Ä‘Ãºng cáº¥u trÃºc thÆ° má»¥c (package chuáº©n),
* hay bá»• sung vÃ­ dá»¥ script train Naive Bayes vá»›i dataset giáº£ láº­p + file `.env` Ä‘á»ƒ cáº¥u hÃ¬nh khÃ³a API LLM?

  Hiá»ƒu rá»“i ğŸ‘. MÃ¬nh sáº½ bá»• sung thÃªm **2 pháº§n** cho báº¡n:

1. **VÃ­ dá»¥ script huáº¥n luyá»‡n Naive Bayes vá»›i dataset giáº£ láº­p** (spam vs ham emails).
2. **File `.env` máº«u** Ä‘á»ƒ cáº¥u hÃ¬nh API key cá»§a LLM (OpenAI, OpenRouter, Grok).

---

### 1. `train_naive_bayes.py`

Script nÃ y táº¡o dataset giáº£ láº­p nhá», train vá»›i `scikit-learn`, sau Ä‘Ã³ lÆ°u model ra file pickle (`naive_bayes_model.pkl`).

```python
# train_naive_bayes.py
import pickle
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

# Dataset giáº£ láº­p
emails = [
    "Win money now, click here",  # spam
    "Congratulations, you won a lottery prize",  # spam
    "Dear friend, please see the attached invoice",  # spam
    "Your account has been compromised, reset password",  # spam
    "Let's meet tomorrow at 10am",  # ham
    "Are you available for the project discussion?",  # ham
    "Please review the attached report",  # ham
    "Lunch at the cafeteria today?",  # ham
]

labels = [
    "spam", "spam", "spam", "spam",
    "ham", "ham", "ham", "ham"
]

# Vectorizer + model
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(emails)

model = MultinomialNB()
model.fit(X, labels)

# Save model + vectorizer
with open("naive_bayes_model.pkl", "wb") as f:
    pickle.dump((vectorizer, model), f)

print("âœ… Naive Bayes model trained and saved as naive_bayes_model.pkl")
```

Khi cháº¡y `python train_naive_bayes.py`, báº¡n sáº½ cÃ³ `naive_bayes_model.pkl`.
Sau nÃ y trong `naive_bayes_filter.py` chá»‰ cáº§n load file nÃ y Ä‘á»ƒ phÃ¢n loáº¡i email.

---

### 2. `.env` file máº«u

```ini
# .env

# OpenAI API
OPENAI_API_KEY=sk-yourkey

# OpenRouter API
OPENROUTER_API_KEY=sk-yourkey

# Grok API
GROK_API_KEY=sk-yourkey

# LLM provider preference (openai | openrouter | grok)
LLM_PROVIDER=openai
```

Trong Python báº¡n cÃ³ thá»ƒ load báº±ng `python-dotenv`:

```python
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
```

---

ğŸ‘‰ Báº¡n cÃ³ muá»‘n mÃ¬nh chá»‰nh luÃ´n pháº§n `naive_bayes_filter.py` trong skeleton code Ä‘á»ƒ **tá»± Ä‘á»™ng load `naive_bayes_model.pkl`** náº¿u cÃ³, thay vÃ¬ stub nhÆ° bÃ¢y giá» khÃ´ng?


  CÃ¢u há»i cá»§a báº¡n ráº¥t thá»±c táº¿ ğŸ‘, mÃ¬nh phÃ¢n tÃ­ch chi tiáº¿t Ä‘á»ƒ báº¡n dá»… hÃ¬nh dung:

---

## 1. Náº¿u thay dataset tiáº¿ng Anh â†’ tiáº¿ng Viá»‡t

* **Naive Bayes** trong scikit-learn khÃ´ng phÃ¢n biá»‡t ngÃ´n ngá»¯.
* Äiá»u quan trá»ng lÃ  **tiá»n xá»­ lÃ½ dá»¯ liá»‡u** (tokenizer, stopwords, tÃ¡ch tá»«).

  * Náº¿u dataset cá»§a báº¡n lÃ  **tiáº¿ng Viá»‡t thuáº§n vÄƒn báº£n** â†’ báº¡n nÃªn dÃ¹ng `underthesea`, `pyvi` hoáº·c `viTokenizer` Ä‘á»ƒ tÃ¡ch tá»« thay vÃ¬ chá»‰ `.split()`.
  * CÃ²n náº¿u dataset Ä‘Ã£ á»Ÿ dáº¡ng "chuá»—i vÄƒn báº£n ngáº¯n, khÃ´ng cáº§n phÃ¢n tÃ¡ch nhiá»u" thÃ¬ giá»¯ nguyÃªn code cÅ©ng cháº¡y Ä‘Æ°á»£c, nhÆ°ng Ä‘á»™ chÃ­nh xÃ¡c sáº½ tháº¥p hÆ¡n.

ğŸ‘‰ TÃ³m láº¡i: **chá»‰ cáº§n thay Ä‘á»•i bÆ°á»›c tiá»n xá»­ lÃ½** náº¿u muá»‘n tá»‘i Æ°u cho tiáº¿ng Viá»‡t, cÃ²n láº¡i train script khÃ´ng cáº§n sá»­a gÃ¬ nhiá»u.

---

## 2. Model sau khi train Ä‘Æ°á»£c lÆ°u á»Ÿ Ä‘Ã¢u?

Trong script `train_naive_bayes.py`, mÃ¬nh Ä‘Ã£ demo lÆ°u model báº±ng **joblib**:

```python
import joblib
joblib.dump(nb_model, "naive_bayes_model.pkl")
```

ğŸ“Œ File `naive_bayes_model.pkl` chÃ­nh lÃ  model Ä‘Ã£ train xong, lÆ°u trong thÆ° má»¥c cháº¡y script.

---

## 3. ChÆ°Æ¡ng trÃ¬nh chÃ­nh load model tháº¿ nÃ o?

Trong **gateway** hoáº·c **service Flask/FastAPI**, báº¡n load model nhÆ° sau:

```python
import joblib

nb_model = joblib.load("naive_bayes_model.pkl")
```

Sau Ä‘Ã³ cÃ³ thá»ƒ gá»i `nb_model.predict([message])` Ä‘á»ƒ phÃ¢n loáº¡i tá»«ng email/message.

---

## 4. Muá»‘n train thÃªm cÃ³ Ä‘Æ°á»£c khÃ´ng?

* **Scikit-learn Naive Bayes (MultinomialNB)** cÃ³ há»— trá»£ **incremental learning** qua hÃ m `partial_fit`.
* Tuy nhiÃªn, code máº«u ban Ä‘áº§u cá»§a mÃ¬nh chá»‰ dÃ¹ng `fit()` (train tá»« Ä‘áº§u).
* Náº¿u muá»‘n train thÃªm, báº¡n cÃ³ 2 lá»±a chá»n:

### (a) Train láº¡i toÃ n bá»™

* Gom dataset cÅ© + dataset má»›i â†’ train láº¡i tá»« Ä‘áº§u vá»›i `fit()`.
* Æ¯u Ä‘iá»ƒm: Ä‘Æ¡n giáº£n, dá»… triá»ƒn khai.
* NhÆ°á»£c: dataset lá»›n thÃ¬ hÆ¡i lÃ¢u.

### (b) Train thÃªm báº±ng `partial_fit`

VÃ­ dá»¥:

```python
nb_model.partial_fit(X_new, y_new, classes=["ham", "spam"])
joblib.dump(nb_model, "naive_bayes_model.pkl")
```

* CÃ¡ch nÃ y há»¯u Ã­ch khi dá»¯ liá»‡u Ä‘áº¿n liÃªn tá»¥c (streaming).
* NhÆ°ng báº¡n pháº£i Ä‘áº£m báº£o khi gá»i `partial_fit` láº§n Ä‘áº§u tiÃªn thÃ¬ pháº£i truyá»n Ä‘áº§y Ä‘á»§ danh sÃ¡ch `classes`.

---

ğŸ‘‰ TÃ³m láº¡i:

* **KhÃ´ng cáº§n thay Ä‘á»•i nhiá»u khi sang tiáº¿ng Viá»‡t**, chá»‰ cáº§n xá»­ lÃ½ tÃ¡ch tá»«.
* **Model lÆ°u ra file `.pkl`** trong thÆ° má»¥c train.
* **ChÆ°Æ¡ng trÃ¬nh chÃ­nh load báº±ng `joblib.load()`**.
* **CÃ³ thá»ƒ train thÃªm** báº±ng `partial_fit`, nhÆ°ng cÃ¡ch dá»… nháº¥t lÃ  train láº¡i toÃ n bá»™.

---

Báº¡n muá»‘n mÃ¬nh viáº¿t thÃªm **phiÃªn báº£n train Naive Bayes tiáº¿ng Viá»‡t vá»›i underthesea + partial\_fit** Ä‘á»ƒ báº¡n test luÃ´n khÃ´ng?


  Chuáº©n luÃ´n ğŸ‘. Náº¿u báº¡n muá»‘n trÃ¡nh `underthesea` (vÃ¬ náº·ng, phá»¥ thuá»™c nhiá»u), ta cÃ³ thá»ƒ chuyá»ƒn sang **Pyvi** â€“ nÃ³ nháº¹ hÆ¡n vÃ  dá»… cÃ i. Báº¡n sáº½ dÃ¹ng `ViTokenizer` Ä‘á»ƒ tÃ¡ch tá»« trÆ°á»›c khi huáº¥n luyá»‡n Naive Bayes.

### Cáº­p nháº­t `train_naive_bayes.py` vá»›i **Pyvi**

```python
import os
import pickle
import pandas as pd
from pyvi import ViTokenizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# ÄÆ°á»ng dáº«n lÆ°u model
MODEL_PATH = "models/naive_bayes_vn.pkl"

def tokenize_vietnamese(text):
    """
    Sá»­ dá»¥ng Pyvi Ä‘á»ƒ tÃ¡ch tá»« cho tiáº¿ng Viá»‡t.
    """
    return ViTokenizer.tokenize(text)

def train_naive_bayes(dataset_path: str):
    # Giáº£ sá»­ dataset cÃ³ 2 cá»™t: "text", "label"
    df = pd.read_csv(dataset_path)

    X = df["text"].astype(str).apply(tokenize_vietnamese)
    y = df["label"]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Pipeline gá»“m vectorizer + Naive Bayes
    pipeline = Pipeline([
        ("vectorizer", CountVectorizer()),
        ("classifier", MultinomialNB())
    ])

    pipeline.fit(X_train, y_train)

    # ÄÃ¡nh giÃ¡ thá»­
    y_pred = pipeline.predict(X_test)
    print(classification_report(y_test, y_pred))

    # LÆ°u model
    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
    with open(MODEL_PATH, "wb") as f:
        pickle.dump(pipeline, f)

    print(f"âœ… Model Ä‘Ã£ lÆ°u táº¡i {MODEL_PATH}")

if __name__ == "__main__":
    # VÃ­ dá»¥ train vá»›i dataset giáº£ láº­p
    train_naive_bayes("datasets/phishing_dataset_vn.csv")
```

---

### Load model trong chÆ°Æ¡ng trÃ¬nh chÃ­nh

```python
import pickle

MODEL_PATH = "models/naive_bayes_vn.pkl"

def load_model():
    with open(MODEL_PATH, "rb") as f:
        model = pickle.load(f)
    return model

# VÃ­ dá»¥ dá»± Ä‘oÃ¡n
if __name__ == "__main__":
    model = load_model()
    test_email = "Xin chÃºc má»«ng, báº¡n Ä‘Ã£ trÃºng thÆ°á»Ÿng 1 tá»· VNÄ!"
    print(model.predict([test_email]))
```

---

### Vá» viá»‡c **train thÃªm**

* Model á»Ÿ Ä‘Ã¢y Ä‘Æ°á»£c lÆ°u báº±ng `pickle`, nÃ³ **khÃ´ng há»— trá»£ incremental training**.
* Náº¿u báº¡n muá»‘n **train thÃªm dá»¯ liá»‡u má»›i**, cÃ¡ch tá»‘t nháº¥t lÃ :

  1. Load láº¡i dataset cÅ© + dá»¯ liá»‡u má»›i â†’ train láº¡i tá»« Ä‘áº§u.
  2. Hoáº·c chuyá»ƒn sang model `sklearn.naive_bayes.MultinomialNB` cÃ³ thá»ƒ dÃ¹ng `partial_fit()` (nhÆ°ng báº¡n cáº§n giá»¯ láº¡i vectorizer consistent).

ğŸ‘‰ Náº¿u dataset cá»§a báº¡n **tÄƒng dáº§n theo thá»i gian**, thÃ¬ mÃ¬nh sáº½ chá»‰nh pipeline Ä‘á»ƒ há»— trá»£ **incremental learning**.

---

Báº¡n cÃ³ muá»‘n mÃ¬nh chá»‰nh láº¡i thÃ nh **pipeline há»— trá»£ `partial_fit`** Ä‘á»ƒ báº¡n cÃ³ thá»ƒ náº¡p thÃªm dá»¯ liá»‡u mÃ  khÃ´ng cáº§n train láº¡i tá»« rá»—ng khÃ´ng?

  
